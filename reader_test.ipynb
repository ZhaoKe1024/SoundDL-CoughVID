{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f51c58-8c4a-40ac-a67a-0c6fe72823d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def CoughVID_Lists(filename=\"../../datasets/waveinfo_annotation.csv\", isdemo=False):\n",
    "    path_list = []\n",
    "    label_list = []\n",
    "    with open(filename, 'r') as fin:\n",
    "        fin.readline()\n",
    "        line = fin.readline()\n",
    "        ind = 0\n",
    "        while line:\n",
    "            parts = line.split(',')\n",
    "            path_list.append(parts[1])\n",
    "            label_list.append(np.array(parts[2], dtype=np.int64))\n",
    "            line = fin.readline()\n",
    "            ind += 1\n",
    "            if isdemo:\n",
    "                if ind > 1000:\n",
    "                    return path_list, label_list\n",
    "    N = len(path_list)\n",
    "    tr, va = int(N * 0.8), int(N * 0.9)\n",
    "    train_path, train_label = path_list[0:tr], label_list[0:tr]\n",
    "    valid_path, valid_label = path_list[tr:va], label_list[tr:va]\n",
    "    test_path, test_label = path_list[va:], label_list[va:]\n",
    "    return train_path, train_label, valid_path, valid_label, test_path, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36ac0b2-588d-4e3c-ae5e-df3273610279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12068\n",
      "12068\n",
      "1508\n",
      "1508\n",
      "1509\n",
      "1509\n"
     ]
    }
   ],
   "source": [
    "print(len(trp))\n",
    "print(len(trl))\n",
    "print(len(vap))\n",
    "print(len(val))\n",
    "print(len(tep))\n",
    "print(len(tel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4582a38-bf90-414c-92cc-36420db53f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "trp, trl, vap, val, tep, tel = CoughVID_Lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e7192-a952-4979-ba56-c053abeae295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:/Program Files (zk)/PythonFiles/AClassification/AudioClassification-Pytorch-KZhao/')\n",
    "from torch.utils.data import Dataset\n",
    "from ackit.data_utils.audio import AudioSegment\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1131be9-9c19-49cb-a040-071a8674e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoughVID_Dataset(Dataset):\n",
    "    def __init__(self, path_list, label_list):\n",
    "        self.path_list = path_list\n",
    "        self.label_list = label_list\n",
    "        self.wav_list = []\n",
    "        for item in tqdm(path_list, desc=\"Loading\"):\n",
    "            self.append_wav(item)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        return self.wav_list[ind], self.label_list[ind]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "\n",
    "    def append_wav(self, file_path):\n",
    "        audioseg = AudioSegment.from_file(file_path)\n",
    "        audioseg.vad()\n",
    "        audioseg.resample(target_sample_rate=16000)\n",
    "        audioseg.crop(duration=3.0, mode=\"train\")\n",
    "        self.wav_list.append(audioseg.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8af2c33e-6440-414a-8df4-c841b9397e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|                                                                                | 0/1509 [00:00<?, ?it/s]C:/Program Files (zk)/PythonFiles/AClassification/AudioClassification-Pytorch-KZhao\\ackit\\data_utils\\audio.py:117: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, sample_rate = librosa.core.load(file)  # , dtype='float32')\n",
      "C:\\Users\\zhaoke\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Loading:   0%|                                                                        | 1/1509 [00:00<21:30,  1.17it/s]C:/Program Files (zk)/PythonFiles/AClassification/AudioClassification-Pytorch-KZhao\\ackit\\data_utils\\audio.py:117: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, sample_rate = librosa.core.load(file)  # , dtype='float32')\n",
      "C:\\Users\\zhaoke\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Loading:   1%|▍                                                                      | 10/1509 [00:01<02:58,  8.40it/s]C:/Program Files (zk)/PythonFiles/AClassification/AudioClassification-Pytorch-KZhao\\ackit\\data_utils\\audio.py:117: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, sample_rate = librosa.core.load(file)  # , dtype='float32')\n",
      "C:\\Users\\zhaoke\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Loading: 100%|█████████████████████████████████████████████████████████████████████| 1509/1509 [01:44<00:00, 14.41it/s]\n"
     ]
    }
   ],
   "source": [
    "cough_dataset = CoughVID_Dataset(tep, tel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc1f273-8a56-4ba5-b72a-b5b1751dcb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 48000])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0,\n",
      "        0, 1, 0, 1, 0, 1, 0, 0])\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.8891, 0.7890, 0.7432, 0.6825, 0.6652, 0.6608,\n",
      "        0.6518, 0.5723, 0.5658, 0.5497, 0.5230, 0.4582, 0.4559, 0.4406, 0.4394,\n",
      "        0.4144, 0.4000, 0.3951, 0.3898, 0.3882, 0.3856, 0.2651, 0.2493, 0.2477,\n",
      "        0.2063, 0.2043, 0.1739, 0.1576, 0.1470])\n"
     ]
    }
   ],
   "source": [
    "from ackit.data_utils.collate_fn import collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(cough_dataset, batch_size=32, shuffle=False,\n",
    "                              collate_fn=collate_fn)\n",
    "for i, (x_wav, y_label, max_len_rate) in enumerate(train_loader):\n",
    "    print(x_wav.shape)\n",
    "    print(y_label)\n",
    "    print(max_len_rate)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
