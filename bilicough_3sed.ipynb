{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad158b51-321f-483e-b919-1f76d19ba266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "WAVE_ROOT = \"G:/DATAS-Medical/BILIBILICOUGH/\"\n",
    "NOISE_ROOT = \"G:/DATAS-Medical/BILINOISE/\"\n",
    "name2label = {\"breathe\": 0, \"cough\": 2, \"clearthroat\": 1, \"exhale\": 3, \"hum\": 4, \"inhale\": 5, \"noise\": 6, \"silence\": 7,\n",
    "              \"sniff\": 8, \"speech\": 9, \"vomit\": 10, \"whooping\": 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0efc9124-b014-41ee-867a-2e82cb1dcc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from readers.bilicough_reader import BiliCoughReader\n",
    "from readers.neucough_reader import NEUCoughReader\n",
    "from readers.coughvid_reader import CoughVIDReader\n",
    "from readers.noise_reader import load_bilinoise_dataset\n",
    "from models.tdnncnn import WSFNN\n",
    "\n",
    "\n",
    "def get_combined_data():\n",
    "    print(\"Build the Dataset consisting of BiliCough, NeuCough, CoughVID19.\")\n",
    "    bcr = BiliCoughReader()\n",
    "    ncr = NEUCoughReader()\n",
    "    cvr = CoughVIDReader()\n",
    "    sample_list, label_list = [], []\n",
    "    tmp_sl, tmp_ll = bcr.get_sample_label_list(mode=\"sed\")\n",
    "    sample_list.extend(tmp_sl)\n",
    "    label_list.extend(tmp_ll)\n",
    "    print(\"bilicough:\", len(label_list))\n",
    "    tmp_sl, tmp_ll = ncr.get_sample_label_list(mode=\"cough\")\n",
    "    sample_list.extend(tmp_sl)\n",
    "    label_list.extend(tmp_ll)\n",
    "    print(\"bilicough+neucough:\", len(label_list))\n",
    "    tmp_sl, tmp_ll = cvr.get_sample_label_list()\n",
    "    sample_list.extend(tmp_sl)\n",
    "    label_list.extend(tmp_ll)\n",
    "    print(\"bilicough+neucough+coughvid:\", len(label_list))\n",
    "    # shuffle\n",
    "    tmplist = list(zip(sample_list, label_list))\n",
    "    random.shuffle(tmplist)\n",
    "    sample_list, label_list = zip(*tmplist)\n",
    "\n",
    "    noise_list, _ = load_bilinoise_dataset(NOISE_ROOT=\"G:/DATAS-Medical/BILINOISE/\", noise_length=bcr.data_length,\n",
    "                                           number=100)\n",
    "    print(\"Loader noise data.\")\n",
    "    return sample_list, label_list, noise_list\n",
    "\n",
    "\n",
    "class BiliCoughDataset(Dataset):\n",
    "    def __init__(self, audioseg, labellist, noises):\n",
    "        self.audioseg = audioseg\n",
    "        self.labellist = labellist\n",
    "        self.noises = noises\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        # When reading waveform data, add noise as data enhancement according to a 1/3 probability.\n",
    "        if random.random() < 0.333:\n",
    "            return self.audioseg[ind] + self.noises[random.randint(0, len(self.noises) - 1)], self.labellist[ind]\n",
    "        else:\n",
    "            return self.audioseg[ind], self.labellist[ind]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audioseg)\n",
    "\n",
    "\n",
    "class SEDModel(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super().__init__()\n",
    "        self.model = WSFNN(class_num=class_num)\n",
    "\n",
    "    def forward(self, x_wav):\n",
    "        return self.wave_conv(x_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de8a45-80aa-4c00-9d0a-3b26619d24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\"batch_size\": 32, \"lr\": 0.001, \"epoch_num\": 30}\n",
    "save_dir = \"./runs/c2sedmodel/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "run_save_dir = save_dir + time.strftime(\"%Y%m%d%H%M\", time.localtime()) + '/'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "save_setting_str = \"Model:{}, optimizer:{}, loss function:{}\\n\".format(\n",
    "            \"VADModel(wav TDNN + mel CNN + pool + mlp)\", \"Adam(lr={})\".format(configs[\"lr\"]),\n",
    "            \"nn.CrossEntropyLoss\")\n",
    "save_setting_str += \"dataset:{}, batch_size:{}, noise_p:{}\\n\".format(\"BiliCough+BiliNoise\",\n",
    "                                                                                  configs[\"batch_size\"], \"0.333\")\n",
    "save_setting_str += \"epoch_num:{},\\n\".format(configs[\"epoch_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e71c9820-0891-4823-9dcc-9e742c50a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Layer of the TDNN: kernel_size:1024, stride:488, padding:512\n",
      "Build TDNN Extractor with 6 Conv1d Layers.\n",
      "Build 2 Convolutional Layer and 1 Pool2d Layer.\n",
      "Pooling after Fusioning the TDNN and CNN.\n",
      "Build 3-Layer MLP as Classifier for 10-class.\n"
     ]
    }
   ],
   "source": [
    "class SEDModel(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super().__init__()\n",
    "        self.model = WSFNN(class_num=class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x=x)\n",
    "model = SEDModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=configs[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae9dbf1-233b-4f91-a66b-cd9b75cee11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the Dataset consisting of BiliCough, NeuCough, CoughVID19.\n",
      "           filename       st       en  label\n",
      "0     bilicough_000  00:01.0  00:01.7      2\n",
      "1     bilicough_000  00:01.7  00:02.2      2\n",
      "2     bilicough_000  00:02.2  00:02.7      2\n",
      "3     bilicough_000  00:03.0  00:03.4      2\n",
      "4     bilicough_000  00:03.4  00:04.0      2\n",
      "...             ...      ...      ...    ...\n",
      "1266  bilicough_018  01:51.3  01:52.3     11\n",
      "1267  bilicough_018  01:52.5  01:52.8      2\n",
      "1268  bilicough_018  01:52.8  01:53.1      2\n",
      "1269  bilicough_018  01:53.1  01:53.5      2\n",
      "1270  bilicough_018  01:54.1  01:55.4      9\n",
      "\n",
      "[1271 rows x 4 columns]\n",
      "sound count:5163, all count:1362.\n",
      "[22050]\n",
      "bilicough: 1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [00:35<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilicough+neucough: 1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2850/2850 [00:10<00:00, 269.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilicough+neucough+coughvid: 4533\n",
      "Loader noise data.\n"
     ]
    }
   ],
   "source": [
    "sample_list, label_list, noise_list = get_combined_data()\n",
    "trte_rate = int(len(sample_list) * 0.9)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            BiliCoughDataset(audioseg=sample_list[:trte_rate], labellist=label_list[:trte_rate], noises=noise_list),\n",
    "            batch_size=configs[\"batch_size\"], shuffle=True)\n",
    "valid_loader = DataLoader(\n",
    "            BiliCoughDataset(audioseg=sample_list[trte_rate:], labellist=label_list[trte_rate:], noises=noise_list),\n",
    "            batch_size=configs[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99699fc6-9996-4914-b1fd-522cdc76b1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data: 4533 4533 100\n"
     ]
    }
   ],
   "source": [
    "print(\"length of data:\", len(sample_list), len(label_list), len(noise_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "324bc060-1128-4bcf-87b7-a758877d735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Dataset...\n",
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 Training : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x y: torch.Size([32, 1, 22050]) torch.Size([32])\n",
      "shape of pred: torch.Size([32, 10])\n",
      "shape of loss_v: torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 Training : 128it [00:05, 25.34it/s] \n",
      "Epoch:1 Training : 128it [00:00, 132.50it/s]\n",
      "Epoch:2 Training : 128it [00:00, 132.78it/s]\n",
      "Epoch:3 Training : 128it [00:00, 131.46it/s]\n",
      "Epoch:4 Training : 128it [00:00, 129.39it/s]\n",
      "Epoch:5 Training : 128it [00:00, 131.69it/s]\n",
      "Epoch:6 Training : 128it [00:00, 139.36it/s]\n",
      "Epoch:7 Training : 128it [00:00, 139.79it/s]\n",
      "Epoch:8 Training : 128it [00:00, 141.36it/s]\n",
      "Epoch:9 Training : 128it [00:00, 137.31it/s]\n",
      "Epoch:10 Training : 128it [00:00, 132.54it/s]\n",
      "Epoch:11 Training : 128it [00:00, 135.65it/s]\n",
      "Epoch:12 Training : 128it [00:00, 132.53it/s]\n",
      "Epoch:13 Training : 128it [00:00, 135.68it/s]\n",
      "Epoch:14 Training : 128it [00:00, 134.54it/s]\n",
      "Epoch:15 Training : 128it [00:00, 133.57it/s]\n",
      "Epoch:16 Training : 128it [00:00, 131.84it/s]\n",
      "Epoch:17 Training : 128it [00:00, 128.97it/s]\n",
      "Epoch:18 Training : 128it [00:01, 127.03it/s]\n",
      "Epoch:19 Training : 128it [00:00, 131.87it/s]\n",
      "Epoch:20 Training : 128it [00:00, 130.57it/s]\n",
      "Epoch:21 Training : 128it [00:00, 131.22it/s]\n",
      "Epoch:22 Training : 128it [00:00, 133.48it/s]\n",
      "Epoch:23 Training : 128it [00:00, 133.31it/s]\n",
      "Epoch:24 Training : 128it [00:00, 132.64it/s]\n",
      "Epoch:25 Training : 128it [00:00, 128.42it/s]\n",
      "Epoch:26 Training : 128it [00:00, 132.78it/s]\n",
      "Epoch:27 Training : 128it [00:00, 132.38it/s]\n",
      "Epoch:28 Training : 128it [00:00, 130.63it/s]\n",
      "Epoch:29 Training : 128it [00:00, 132.38it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Build Dataset...\")\n",
    "flag = False\n",
    "Loss_Epoch_List = []\n",
    "print(\"Start Training...\")\n",
    "for epoch_id in range(configs[\"epoch_num\"]):\n",
    "    model.train()\n",
    "    Loss_Batch_List = []\n",
    "    for batch_id, (x_wav, y_lab) in tqdm(enumerate(train_loader),\n",
    "                                         desc=\"Epoch:{} Training \".format(epoch_id)):\n",
    "        optimizer.zero_grad()\n",
    "        x_wav, y_lab = x_wav.to(device).unsqueeze(1).to(torch.float32), y_lab.to(device)  # .to(torch.float32)\n",
    "        if not flag:\n",
    "            print(\"shape of x y:\", x_wav.shape, y_lab.shape)\n",
    "        y_pred = model(x=x_wav)\n",
    "        if not flag:\n",
    "            print(\"shape of pred:\", y_pred.shape)\n",
    "        loss_v = criterion(input=y_pred, target=y_lab)\n",
    "        if not flag:\n",
    "            print(\"shape of loss_v:\", loss_v.shape)\n",
    "            flag = True\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        Loss_Batch_List.append(loss_v.mean().item())\n",
    "    Loss_Epoch_List.append(np.array(Loss_Batch_List).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ab8b22-1881-4fa1-8a89-4bdf4b6f5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models were saved.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(run_save_dir):\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "settingf = open(run_save_dir + \"train_settings.txt\", 'w')\n",
    "settingf.write(save_setting_str)\n",
    "settingf.write(\"loss:[\" + \",\".join([str(it) for it in Loss_Epoch_List]) + ']\\n')\n",
    "settingf.close()\n",
    "torch.save(model.state_dict(),\n",
    "           run_save_dir + \"vad_model_epoch{}.pth\".format(configs[\"epoch_num\"]))\n",
    "torch.save(optimizer.state_dict(),\n",
    "           run_save_dir + \"vad_optimizer_epoch{}.pth\".format(configs[\"epoch_num\"]))\n",
    "print(\"models were saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa99c2e3-a8a0-4c92-a2fd-698e8ea71d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Layer of the TDNN: kernel_size:1024, stride:488, padding:512\n",
      "Build TDNN Extractor with 6 Conv1d Layers.\n",
      "Build 2 Convolutional Layer and 1 Pool2d Layer.\n",
      "Pooling after Fusioning the TDNN and CNN.\n",
      "Build 3-Layer MLP as Classifier for 10-class.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SEDModel(\n",
       "  (model): WSFNN(\n",
       "    (mel_extractor): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (wave_conv): TDNN_Extractor(\n",
       "      (wav2mel): Conv1d(1, 128, kernel_size=(1024,), stride=(488,), padding=(512,), bias=False)\n",
       "      (layer_norm): LayerNorm((46,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer1): Conv1d(128, 512, kernel_size=(5,), stride=(1,))\n",
       "      (bn1): LayerNorm((42,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(2,), groups=512)\n",
       "      (bn2): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(3,), groups=512)\n",
       "      (bn3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer4): Conv1d(512, 512, kernel_size=(1,), stride=(1,), groups=512)\n",
       "      (bn4): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), groups=512)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (mel_conv): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SiLU()\n",
       "      (6): AdaptiveAvgPool2d(output_size=(None, 32))\n",
       "    )\n",
       "    (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (3): SiLU()\n",
       "      (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vad_model = SEDModel()\n",
    "vad_model.load_state_dict(torch.load(\"./runs/c2sedmodel/202502161815/sed_model_epoch30.pth\"))\n",
    "vad_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e21e3eea-569b-4ab2-9708-9729f6ed4667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing...: 7it [00:00, 61.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 22050])\n",
      "[0.96875]\n",
      "[0.96875]\n",
      "[0.96875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875]\n",
      "[0.96875, 0.96875]\n",
      "[0.96875, 0.96875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0, 0.96875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [22050] at entry 0 and [23815] at entry 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m acc_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_id, (x_wav, y_lab) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(valid_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting...\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      8\u001b[0m         x_wav \u001b[38;5;241m=\u001b[39m x_wav\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [22050] at entry 0 and [23815] at entry 5"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "pre_list = []\n",
    "rec_list = []\n",
    "acc_list = []\n",
    "from sklearn import metrics\n",
    "for batch_id, (x_wav, y_lab) in tqdm(enumerate(valid_loader), desc=\"Testing...\"):\n",
    "    with torch.no_grad():\n",
    "        x_wav = x_wav.to(device).unsqueeze(1).to(torch.float32)\n",
    "        print(x_wav.shape)\n",
    "        y_pred = model(x=x_wav)\n",
    "        y_pred = np.argmax(y_pred.data.cpu().numpy(), axis=1)\n",
    "\n",
    "        precision = metrics.precision_score(y_true=y_lab, y_pred=y_pred, average=\"micro\")\n",
    "        recall = metrics.recall_score(y_true=y_lab, y_pred=y_pred, average=\"micro\")\n",
    "        acc = metrics.accuracy_score(y_true=y_lab, y_pred=y_pred)\n",
    "        pre_list.append(precision)\n",
    "        rec_list.append(recall)\n",
    "        acc_list.append(acc)\n",
    "        print(pre_list)\n",
    "        print(rec_list)\n",
    "        print(acc_list)\n",
    "print(\"precision:\")\n",
    "print(pre_list)\n",
    "print(\"recall:\")\n",
    "print(rec_list)\n",
    "print(\"accuracy:\")\n",
    "print(acc_list)\n",
    "if not os.path.exists(run_save_dir):\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(list(range(len(Loss_Epoch_List))), np.array(Loss_Epoch_List), c=\"black\")\n",
    "plt.savefig(run_save_dir + \"vad_meanloss_epoch.png\", dpi=300, format=\"png\")\n",
    "plt.close(0)\n",
    "\n",
    "settingf = open(run_save_dir + \"train_settings.txt\", 'w')\n",
    "settingf.write(save_setting_str)\n",
    "settingf.write(\"loss:[\" + \",\".join([str(it) for it in Loss_Epoch_List]) + ']\\n')\n",
    "settingf.write('precision:{}['.format(np.mean(pre_list)) + \",\".join([str(it) for it in pre_list]) + ']\\n')\n",
    "settingf.write('recall:{}['.format(np.mean(rec_list)) + \",\".join([str(it) for it in rec_list]) + ']\\n')\n",
    "settingf.write('accuracy:{}['.format(np.mean(acc_list)) + \",\".join([str(it) for it in acc_list]) + ']\\n')\n",
    "# plt.show()\n",
    "settingf.close()\n",
    "\n",
    "torch.save(model.state_dict(),\n",
    "           run_save_dir + \"vad_model_epoch{}.pth\".format(configs[\"epoch_num\"]))\n",
    "torch.save(optimizer.state_dict(),\n",
    "           run_save_dir + \"vad_optimizer_epoch{}.pth\".format(configs[\"epoch_num\"]))\n",
    "print(\"models were saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd71a4c-4b59-407f-ad91-17d74f45de4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff82390-d87e-4c48-8a09-d066d3a849b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
