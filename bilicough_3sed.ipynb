{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad158b51-321f-483e-b919-1f76d19ba266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "WAVE_ROOT = \"G:/DATAS-Medical/BILIBILICOUGH/\"\n",
    "NOISE_ROOT = \"G:/DATAS-Medical/BILINOISE/\"\n",
    "name2label = {\"breathe\": 0, \"cough\": 2, \"clearthroat\": 1, \"exhale\": 3, \"hum\": 4, \"inhale\": 5, \"noise\": 6, \"silence\": 7,\n",
    "              \"sniff\": 8, \"speech\": 9, \"vomit\": 10, \"whooping\": 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0efc9124-b014-41ee-867a-2e82cb1dcc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from readers.bilicough_reader import BiliCoughReader\n",
    "from readers.neucough_reader import NEUCoughReader\n",
    "from readers.coughvid_reader import CoughVIDReader\n",
    "from readers.noise_reader import load_bilinoise_dataset\n",
    "from models.tdnncnn import WSFNN\n",
    "\n",
    "\n",
    "def get_combined_data():\n",
    "    print(\"Build the Dataset consisting of BiliCough, NeuCough, CoughVID19.\")\n",
    "    bcr = BiliCoughReader()\n",
    "    ncr = NEUCoughReader()\n",
    "    cvr = CoughVIDReader()\n",
    "    sample_list, label_list = [], []\n",
    "    tmp_sl, tmp_ll = bcr.get_sample_label_list(mode=\"sed\")\n",
    "    sample_list.extend(tmp_sl)\n",
    "    label_list.extend(tmp_ll)\n",
    "    print(\"bilicough:\", len(label_list))\n",
    "    tmp_sl, tmp_ll = ncr.get_sample_label_list(mode=\"cough\")\n",
    "    sample_list.extend(tmp_sl)\n",
    "    label_list.extend(tmp_ll)\n",
    "    print(\"bilicough+neucough:\", len(label_list))\n",
    "    tmp_sl, tmp_ll = cvr.get_sample_label_list()\n",
    "    sample_list.extend(tmp_sl)\n",
    "    label_list.extend(tmp_ll)\n",
    "    print(\"bilicough+neucough+coughvid:\", len(label_list))\n",
    "    # shuffle\n",
    "    tmplist = list(zip(sample_list, label_list))\n",
    "    random.shuffle(tmplist)\n",
    "    sample_list, label_list = zip(*tmplist)\n",
    "\n",
    "    noise_list, _ = load_bilinoise_dataset(NOISE_ROOT=\"G:/DATAS-Medical/BILINOISE/\", noise_length=bcr.data_length,\n",
    "                                           number=100)\n",
    "    print(\"Loader noise data.\")\n",
    "    return sample_list, label_list, noise_list\n",
    "\n",
    "\n",
    "class BiliCoughDataset(Dataset):\n",
    "    def __init__(self, audioseg, labellist, noises):\n",
    "        self.audioseg = audioseg\n",
    "        self.labellist = labellist\n",
    "        self.noises = noises\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        # When reading waveform data, add noise as data enhancement according to a 1/3 probability.\n",
    "        if random.random() < 0.333:\n",
    "            return self.audioseg[ind] + self.noises[random.randint(0, len(self.noises) - 1)], self.labellist[ind]\n",
    "        else:\n",
    "            return self.audioseg[ind], self.labellist[ind]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audioseg)\n",
    "\n",
    "\n",
    "class SEDModel(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super().__init__()\n",
    "        self.model = WSFNN(class_num=class_num)\n",
    "\n",
    "    def forward(self, x_wav):\n",
    "        return self.wave_conv(x_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8de8a45-80aa-4c00-9d0a-3b26619d24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\"batch_size\": 32, \"lr\": 0.001, \"epoch_num\": 30}\n",
    "save_dir = \"./runs/c2sedmodel/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "run_save_dir = save_dir + time.strftime(\"%Y%m%d%H%M\", time.localtime()) + '/'\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "save_setting_str = \"Model:{}, optimizer:{}, loss function:{}\\n\".format(\n",
    "            \"VADModel(wav TDNN + mel CNN + pool + mlp)\", \"Adam(lr={})\".format(configs[\"lr\"]),\n",
    "            \"nn.CrossEntropyLoss\")\n",
    "save_setting_str += \"dataset:{}, batch_size:{}, noise_p:{}\\n\".format(\"BiliCough+BiliNoise\",\n",
    "                                                                                  configs[\"batch_size\"], \"0.333\")\n",
    "save_setting_str += \"epoch_num:{},\\n\".format(configs[\"epoch_num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e71c9820-0891-4823-9dcc-9e742c50a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Layer of the TDNN: kernel_size:1024, stride:488, padding:512\n",
      "Build TDNN Extractor with 6 Conv1d Layers.\n",
      "Build 2 Convolutional Layer and 1 Pool2d Layer.\n",
      "Pooling after Fusioning the TDNN and CNN.\n",
      "Build 3-Layer MLP as Classifier for 10-class.\n"
     ]
    }
   ],
   "source": [
    "class SEDModel(nn.Module):\n",
    "    def __init__(self, class_num=10):\n",
    "        super().__init__()\n",
    "        self.model = WSFNN(class_num=class_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x=x)\n",
    "model = SEDModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=configs[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dae9dbf1-233b-4f91-a66b-cd9b75cee11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build the Dataset consisting of BiliCough, NeuCough, CoughVID19.\n",
      "           filename       st       en  label\n",
      "0     bilicough_000  00:01.0  00:01.7      2\n",
      "1     bilicough_000  00:01.7  00:02.2      2\n",
      "2     bilicough_000  00:02.2  00:02.7      2\n",
      "3     bilicough_000  00:03.0  00:03.4      2\n",
      "4     bilicough_000  00:03.4  00:04.0      2\n",
      "...             ...      ...      ...    ...\n",
      "1266  bilicough_018  01:51.3  01:52.3     11\n",
      "1267  bilicough_018  01:52.5  01:52.8      2\n",
      "1268  bilicough_018  01:52.8  01:53.1      2\n",
      "1269  bilicough_018  01:53.1  01:53.5      2\n",
      "1270  bilicough_018  01:54.1  01:55.4      9\n",
      "\n",
      "[1271 rows x 4 columns]\n",
      "sound count:5163, all count:1362.\n",
      "[22050]\n",
      "bilicough: 1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 321/321 [00:35<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilicough+neucough: 1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2850/2850 [00:10<00:00, 269.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilicough+neucough+coughvid: 4533\n",
      "Loader noise data.\n"
     ]
    }
   ],
   "source": [
    "sample_list, label_list, noise_list = get_combined_data()\n",
    "trte_rate = int(len(sample_list) * 0.9)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "            BiliCoughDataset(audioseg=sample_list[:trte_rate], labellist=label_list[:trte_rate], noises=noise_list),\n",
    "            batch_size=configs[\"batch_size\"], shuffle=True)\n",
    "valid_loader = DataLoader(\n",
    "            BiliCoughDataset(audioseg=sample_list[trte_rate:], labellist=label_list[trte_rate:], noises=noise_list),\n",
    "            batch_size=configs[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99699fc6-9996-4914-b1fd-522cdc76b1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of data: 4533 4533 100\n"
     ]
    }
   ],
   "source": [
    "print(\"length of data:\", len(sample_list), len(label_list), len(noise_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "324bc060-1128-4bcf-87b7-a758877d735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Dataset...\n",
      "Start Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 Training : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x y: torch.Size([32, 1, 22050]) torch.Size([32])\n",
      "shape of pred: torch.Size([32, 10])\n",
      "shape of loss_v: torch.Size([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:0 Training : 128it [00:05, 25.34it/s] \n",
      "Epoch:1 Training : 128it [00:00, 132.50it/s]\n",
      "Epoch:2 Training : 128it [00:00, 132.78it/s]\n",
      "Epoch:3 Training : 128it [00:00, 131.46it/s]\n",
      "Epoch:4 Training : 128it [00:00, 129.39it/s]\n",
      "Epoch:5 Training : 128it [00:00, 131.69it/s]\n",
      "Epoch:6 Training : 128it [00:00, 139.36it/s]\n",
      "Epoch:7 Training : 128it [00:00, 139.79it/s]\n",
      "Epoch:8 Training : 128it [00:00, 141.36it/s]\n",
      "Epoch:9 Training : 128it [00:00, 137.31it/s]\n",
      "Epoch:10 Training : 128it [00:00, 132.54it/s]\n",
      "Epoch:11 Training : 128it [00:00, 135.65it/s]\n",
      "Epoch:12 Training : 128it [00:00, 132.53it/s]\n",
      "Epoch:13 Training : 128it [00:00, 135.68it/s]\n",
      "Epoch:14 Training : 128it [00:00, 134.54it/s]\n",
      "Epoch:15 Training : 128it [00:00, 133.57it/s]\n",
      "Epoch:16 Training : 128it [00:00, 131.84it/s]\n",
      "Epoch:17 Training : 128it [00:00, 128.97it/s]\n",
      "Epoch:18 Training : 128it [00:01, 127.03it/s]\n",
      "Epoch:19 Training : 128it [00:00, 131.87it/s]\n",
      "Epoch:20 Training : 128it [00:00, 130.57it/s]\n",
      "Epoch:21 Training : 128it [00:00, 131.22it/s]\n",
      "Epoch:22 Training : 128it [00:00, 133.48it/s]\n",
      "Epoch:23 Training : 128it [00:00, 133.31it/s]\n",
      "Epoch:24 Training : 128it [00:00, 132.64it/s]\n",
      "Epoch:25 Training : 128it [00:00, 128.42it/s]\n",
      "Epoch:26 Training : 128it [00:00, 132.78it/s]\n",
      "Epoch:27 Training : 128it [00:00, 132.38it/s]\n",
      "Epoch:28 Training : 128it [00:00, 130.63it/s]\n",
      "Epoch:29 Training : 128it [00:00, 132.38it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Build Dataset...\")\n",
    "flag = False\n",
    "Loss_Epoch_List = []\n",
    "print(\"Start Training...\")\n",
    "for epoch_id in range(configs[\"epoch_num\"]):\n",
    "    model.train()\n",
    "    Loss_Batch_List = []\n",
    "    for batch_id, (x_wav, y_lab) in tqdm(enumerate(train_loader),\n",
    "                                         desc=\"Epoch:{} Training \".format(epoch_id)):\n",
    "        optimizer.zero_grad()\n",
    "        x_wav, y_lab = x_wav.to(device).unsqueeze(1).to(torch.float32), y_lab.to(device)  # .to(torch.float32)\n",
    "        if not flag:\n",
    "            print(\"shape of x y:\", x_wav.shape, y_lab.shape)\n",
    "        y_pred = model(x=x_wav)\n",
    "        if not flag:\n",
    "            print(\"shape of pred:\", y_pred.shape)\n",
    "        loss_v = criterion(input=y_pred, target=y_lab)\n",
    "        if not flag:\n",
    "            print(\"shape of loss_v:\", loss_v.shape)\n",
    "            flag = True\n",
    "        loss_v.backward()\n",
    "        optimizer.step()\n",
    "        Loss_Batch_List.append(loss_v.mean().item())\n",
    "    Loss_Epoch_List.append(np.array(Loss_Batch_List).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ab8b22-1881-4fa1-8a89-4bdf4b6f5a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models were saved.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(run_save_dir):\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "settingf = open(run_save_dir + \"train_settings.txt\", 'w')\n",
    "settingf.write(save_setting_str)\n",
    "settingf.write(\"loss:[\" + \",\".join([str(it) for it in Loss_Epoch_List]) + ']\\n')\n",
    "settingf.close()\n",
    "torch.save(model.state_dict(),\n",
    "           run_save_dir + \"vad_model_epoch{}.pth\".format(configs[\"epoch_num\"]))\n",
    "torch.save(optimizer.state_dict(),\n",
    "           run_save_dir + \"vad_optimizer_epoch{}.pth\".format(configs[\"epoch_num\"]))\n",
    "print(\"models were saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa99c2e3-a8a0-4c92-a2fd-698e8ea71d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Layer of the TDNN: kernel_size:1024, stride:488, padding:512\n",
      "Build TDNN Extractor with 6 Conv1d Layers.\n",
      "Build 2 Convolutional Layer and 1 Pool2d Layer.\n",
      "Pooling after Fusioning the TDNN and CNN.\n",
      "Build 3-Layer MLP as Classifier for 10-class.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SEDModel(\n",
       "  (model): WSFNN(\n",
       "    (mel_extractor): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (wave_conv): TDNN_Extractor(\n",
       "      (wav2mel): Conv1d(1, 128, kernel_size=(1024,), stride=(488,), padding=(512,), bias=False)\n",
       "      (layer_norm): LayerNorm((46,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer1): Conv1d(128, 512, kernel_size=(5,), stride=(1,))\n",
       "      (bn1): LayerNorm((42,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(2,), groups=512)\n",
       "      (bn2): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(3,), groups=512)\n",
       "      (bn3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer4): Conv1d(512, 512, kernel_size=(1,), stride=(1,), groups=512)\n",
       "      (bn4): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), groups=512)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (mel_conv): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SiLU()\n",
       "      (6): AdaptiveAvgPool2d(output_size=(None, 32))\n",
       "    )\n",
       "    (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (3): SiLU()\n",
       "      (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vad_model = SEDModel()\n",
    "vad_model.load_state_dict(torch.load(\"./runs/c2sedmodel/202502161815/sed_model_epoch30.pth\"))\n",
    "vad_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e21e3eea-569b-4ab2-9708-9729f6ed4667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing...: 7it [00:00, 61.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 22050])\n",
      "[0.96875]\n",
      "[0.96875]\n",
      "[0.96875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875]\n",
      "[0.96875, 0.96875]\n",
      "[0.96875, 0.96875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0]\n",
      "torch.Size([32, 1, 22050])\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0, 0.96875]\n",
      "[0.96875, 0.96875, 0.96875, 0.96875, 0.875, 1.0, 0.96875]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [22050] at entry 0 and [23815] at entry 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m acc_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_id, (x_wav, y_lab) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(valid_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting...\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      8\u001b[0m         x_wav \u001b[38;5;241m=\u001b[39m x_wav\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:143\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:172\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:163\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    162\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [22050] at entry 0 and [23815] at entry 5"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "pre_list = []\n",
    "rec_list = []\n",
    "acc_list = []\n",
    "from sklearn import metrics\n",
    "for batch_id, (x_wav, y_lab) in tqdm(enumerate(valid_loader), desc=\"Testing...\"):\n",
    "    with torch.no_grad():\n",
    "        x_wav = x_wav.to(device).unsqueeze(1).to(torch.float32)\n",
    "        print(x_wav.shape)\n",
    "        y_pred = model(x=x_wav)\n",
    "        y_pred = np.argmax(y_pred.data.cpu().numpy(), axis=1)\n",
    "\n",
    "        precision = metrics.precision_score(y_true=y_lab, y_pred=y_pred, average=\"micro\")\n",
    "        recall = metrics.recall_score(y_true=y_lab, y_pred=y_pred, average=\"micro\")\n",
    "        acc = metrics.accuracy_score(y_true=y_lab, y_pred=y_pred)\n",
    "        pre_list.append(precision)\n",
    "        rec_list.append(recall)\n",
    "        acc_list.append(acc)\n",
    "        print(pre_list)\n",
    "        print(rec_list)\n",
    "        print(acc_list)\n",
    "print(\"precision:\")\n",
    "print(pre_list)\n",
    "print(\"recall:\")\n",
    "print(rec_list)\n",
    "print(\"accuracy:\")\n",
    "print(acc_list)\n",
    "if not os.path.exists(run_save_dir):\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(list(range(len(Loss_Epoch_List))), np.array(Loss_Epoch_List), c=\"black\")\n",
    "plt.savefig(run_save_dir + \"vad_meanloss_epoch.png\", dpi=300, format=\"png\")\n",
    "plt.close(0)\n",
    "\n",
    "settingf = open(run_save_dir + \"train_settings.txt\", 'w')\n",
    "settingf.write(save_setting_str)\n",
    "settingf.write(\"loss:[\" + \",\".join([str(it) for it in Loss_Epoch_List]) + ']\\n')\n",
    "settingf.write('precision:{}['.format(np.mean(pre_list)) + \",\".join([str(it) for it in pre_list]) + ']\\n')\n",
    "settingf.write('recall:{}['.format(np.mean(rec_list)) + \",\".join([str(it) for it in rec_list]) + ']\\n')\n",
    "settingf.write('accuracy:{}['.format(np.mean(acc_list)) + \",\".join([str(it) for it in acc_list]) + ']\\n')\n",
    "# plt.show()\n",
    "settingf.close()\n",
    "\n",
    "torch.save(model.state_dict(),\n",
    "           run_save_dir + \"vad_model_epoch{}.pth\".format(configs[\"epoch_num\"]))\n",
    "torch.save(optimizer.state_dict(),\n",
    "           run_save_dir + \"vad_optimizer_epoch{}.pth\".format(configs[\"epoch_num\"]))\n",
    "print(\"models were saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ce9c6-b2a4-4e1b-898d-38a88ab5b6d5",
   "metadata": {},
   "source": [
    "# Training End.\n",
    "# Detection SED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabb4deb-eb6e-4a2d-8244-01dc1c0a0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# sys.path.append(r'D:/PythonTorchVITS/MedicalSignal/SoundDL-CoughVID')\n",
    "sys.path.append(r'C:/Program Files (zk)/PythonFiles/AClassification/SoundDL-CoughVID')\n",
    "from chapter2_SEDmodel import SEDModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed21278-cba7-4328-98d7-b01f6aeed53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first Layer of the TDNN: kernel_size:1024, stride:488, padding:512\n",
      "Build TDNN Extractor with 6 Conv1d Layers.\n",
      "Build 2 Convolutional Layer and 1 Pool2d Layer.\n",
      "Pooling after Fusioning the TDNN and CNN.\n",
      "Build 3-Layer MLP as Classifier for 10-class.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SEDModel(\n",
       "  (model): WSFNN(\n",
       "    (mel_extractor): MelSpectrogram(\n",
       "      (spectrogram): Spectrogram()\n",
       "      (mel_scale): MelScale()\n",
       "    )\n",
       "    (wave_conv): TDNN_Extractor(\n",
       "      (wav2mel): Conv1d(1, 128, kernel_size=(1024,), stride=(488,), padding=(512,), bias=False)\n",
       "      (layer_norm): LayerNorm((46,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer1): Conv1d(128, 512, kernel_size=(5,), stride=(1,))\n",
       "      (bn1): LayerNorm((42,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(2,), groups=512)\n",
       "      (bn2): LayerNorm((38,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), dilation=(3,), groups=512)\n",
       "      (bn3): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer4): Conv1d(512, 512, kernel_size=(1,), stride=(1,), groups=512)\n",
       "      (bn4): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (td_layer5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), groups=512)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    )\n",
       "    (mel_conv): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU()\n",
       "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SiLU()\n",
       "      (6): AdaptiveAvgPool2d(output_size=(None, 32))\n",
       "    )\n",
       "    (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (3): SiLU()\n",
       "      (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"./runs/c2sedmodel/\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "sed_model = SEDModel()\n",
    "sed_model.load_state_dict(torch.load(save_dir+\"202502161815/sed_model_epoch30.pth\"))\n",
    "sed_model.to(device)\n",
    "sed_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a25cc8-52dc-4ee7-b3b2-0695b8d55156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273\n",
      "batch num:9, batch shape:torch.Size([32, 22050])\n"
     ]
    }
   ],
   "source": [
    "testwav, sr = librosa.load(\"F:/DATAS/NEUCOUGHDATA_FULL/20240921133332_audiodata_元音字母a.wav\")\n",
    "N = len(testwav)\n",
    "maxv = max(testwav)\n",
    "seg_list = []\n",
    "st, step, overlap = 0, 22050, 22050//3\n",
    "while st+step<=N:\n",
    "    seg_list.append(testwav[st:st+step])\n",
    "    st = st+step-overlap\n",
    "tmp = testwav[st:]\n",
    "new_tmp = np.zeros(step)\n",
    "st = (step-len(tmp))//2\n",
    "new_tmp[st:st+len(tmp)] = tmp\n",
    "seg_list.append(new_tmp)\n",
    "print(len(seg_list))\n",
    "\n",
    "seg_list = [torch.from_numpy(it) for it in seg_list]\n",
    "\n",
    "batch_size = 32\n",
    "x_batchs = []\n",
    "ind = 0\n",
    "while ind+batch_size < len(seg_list):\n",
    "    x_batchs.append(torch.stack(seg_list[ind:ind+batch_size], dim=0))\n",
    "    ind += batch_size\n",
    "x_batchs.append(torch.stack(seg_list[ind:], dim=0))\n",
    "print(\"batch num:{}, batch shape:{}\".format(len(x_batchs), x_batchs[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80b936a-8ed6-4a28-a18f-b006a4c19e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = None\n",
    "for batch_id, x_wav in enumerate(x_batchs):\n",
    "    with torch.no_grad():\n",
    "        y_pred = sed_model(x=x_wav.to(device).unsqueeze(1).to(torch.float32))\n",
    "        if pred_list is None:\n",
    "            pred_list = y_pred\n",
    "        else:\n",
    "            pred_list = torch.concat((pred_list, y_pred), dim=0)\n",
    "pred_list = np.argmax(pred_list.data.cpu().numpy(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "435d6587-f7b8-4a2b-974a-074372e1b782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 7 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 7 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 7 2 2\n",
      " 2 2 2 2 2 2 7 4 4 2 2 2 2 2 2 2 2 2 7 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 7\n",
      " 2 2 2 2 2 2 2 2 7 2 7 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 7 2 2 2 2 2 2 2 2 2\n",
      " 2 2 7 7 2 2 2 2 2 2 2 2 2 2]\n",
      "<generator object <genexpr> at 0x000002028A965430>\n"
     ]
    }
   ],
   "source": [
    "print(pred_list)\n",
    "sed_label2name = {0: \"breathe\", 1: \"clearthroat\", 2: \"cough\", 3: \"exhale\", 4: \"hum\", 5: \"inhale\",\n",
    "                               6: \"sniff\", 7: \"speech\", 8: \"vomit\", 9: \"whooping\"}\n",
    "print(sed_label2name[it] for it in pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55226664-2523-4152-8127-de97660b0538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
