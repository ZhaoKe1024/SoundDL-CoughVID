{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d187c82-8fee-4576-abfb-b47d317ce549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "ROOT = \"F:/DATAS/COUGHVID-public_dataset_v3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce9971-e1c1-4235-8b5d-efac85a3b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed_value= 32 \n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# set variables\n",
    "ROOT = 'F:/DATAS/COUGHVID-public_dataset_v3/coughvid_20211012/'\n",
    "class_names = ['healthy','COVID-19','symptomatic']\n",
    "audio_length = 32306\n",
    "\n",
    "# load coughvid meta\n",
    "data_raw = pd.read_csv(ROOT+'metadata_compiled.csv', header=0, index_col=0)\n",
    "data_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485b4b9-8ccc-457b-b051-b140333f7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_raw.groupby(\"status\")[\"uuid\"].count()\n",
    "data_raw.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ccca0-21d1-4fc1-8d22-74a9a87a3d9d",
   "metadata": {},
   "source": [
    "# Step3 读取切分后的数据，抽取特征，创建pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0efc14-70a9-42cc-ba07-924fe0839ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(ROOT+'waveinfo_fewtoml_split.csv', header=0, index_col=0)\n",
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f437a0-90c5-46b6-ab22-45c74b9d5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"labels:\")\n",
    "print(data_raw.groupby(\"status\")[\"uuid\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616a067-63fc-49be-8c69-c3374a781bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOP_LENGTH = 512        # number of samples between successive frames\n",
    "WINDOW_LENGTH = 512     # length of the window in samples\n",
    "N_MEL = 128             # number of Mel bands to generate\n",
    "\n",
    "def compute_melspectrogram_with_fixed_length(audio, sampling_rate, num_of_samples=86):\n",
    "    try:\n",
    "        # compute a mel-scaled spectrogram\n",
    "        melspectrogram = librosa.feature.melspectrogram(y=audio, \n",
    "                                                        sr=sampling_rate, \n",
    "                                                        hop_length=HOP_LENGTH,\n",
    "                                                        win_length=WINDOW_LENGTH, \n",
    "                                                        n_mels=N_MEL)\n",
    "\n",
    "        # convert a power spectrogram to decibel units (log-mel spectrogram)\n",
    "        melspectrogram_db = librosa.power_to_db(melspectrogram, ref=np.max)\n",
    "        \n",
    "        melspectrogram_length = melspectrogram_db.shape[1]\n",
    "        # # pad or fix the length of spectrogram \n",
    "        # if melspectrogram_length != num_of_samples:\n",
    "        #     melspectrogram_db = librosa.util.fix_length(melspectrogram_db, \n",
    "        #                                                 size=num_of_samples, \n",
    "        #                                                 axis=1, \n",
    "        #                                                 constant_values=(0, -80.0))\n",
    "        print(melspectrogram_db.shape)\n",
    "    except Exception as e:\n",
    "        print(\"\\nError encountered while parsing files\\n>>\", e)\n",
    "        return None \n",
    "    \n",
    "    return melspectrogram_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63a734-9f97-4ab3-9994-bae919a5f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_length = 32306\n",
    "# sample_rate = 22050\n",
    "all_data = []\n",
    "all_fname = []\n",
    "all_sr = []\n",
    "all_labels = []\n",
    "m2l = {\"healthy\":0, \"COVID-19\":1}\n",
    "# new_df = df_f\n",
    "maxi, mini = 0, 999999\n",
    "for idx, row in tqdm(enumerate(data_raw.itertuples()), total=len(data_raw)):\n",
    "    fname = ROOT+\"coughvid_20211012_fine/\" +getattr(row, \"uuid\")+\".wav\"\n",
    "    label = getattr(row, \"uuid\")\n",
    "    # load sound sample\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(fname, mono=True)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        print(\"Error file:\", fname)\n",
    "        continue\n",
    "    maxi = max(maxi, audio.shape[0]/sample_rate)\n",
    "    mini = min(mini, audio.shape[0]/sample_rate)\n",
    "    \n",
    "\n",
    "    # feature = extract_features(audio_pad, sample_rate)\n",
    "    #print(len(feature))\n",
    "    # all_data.append(feature)\n",
    "    all_data.append(audio)\n",
    "    all_fname.append(fname)\n",
    "    all_labels.append(m2l[getattr(row, \"status\")])\n",
    "    all_sr.append(sample_rate)\n",
    "#     new_df = pd.concat([new_df, df_f.iloc[[idx], :]], axis=0)\n",
    "# new_df = new_df.iloc[len(df_f):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6365400-aee1-4806-b3d7-8c1eaf44fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_data), len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c754c-9261-4884-859d-1cdfd7a8d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = []\n",
    "features_2 = []\n",
    "# \n",
    "for i in tqdm(range(len(all_data)),desc=\"calc..\"):\n",
    "    melspect = compute_melspectrogram_with_fixed_length(all_data[i], all_sr[i])\n",
    "    # print(melspec.shape)\n",
    "    # melspects.append(melspect)\n",
    "    # print(neg_idx, pos_idx)\n",
    "    if all_labels[i] == 0:\n",
    "        features_1.append([melspect, 0])\n",
    "    else:\n",
    "        features_2.append([melspect, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3efa24-b953-47dc-8642-2463be7f3b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features.extend(features_1)\n",
    "features.extend(features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b93059-cf3d-43e3-99d2-26b73284ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "us8k_df = pd.DataFrame(features, columns=[\"melspectrogram\", \"label\"])\n",
    "us8k_df.to_pickle(ROOT+\"coughvid_split_specdf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d561af-417c-4941-a98c-f822941f3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(ROOT+\"coughvid_split_specdf.pkl\")\n",
    "neg_list = list(range(2076))\n",
    "pos_list = list(range(2076, 2850))\n",
    "print(df.iloc[neg_list, :].groupby(\"label\")[\"melspectrogram\"].count())\n",
    "print(df.iloc[pos_list, :].groupby(\"label\")[\"melspectrogram\"].count())\n",
    "# for item in df.itertuples():\n",
    "    # print(getattr(item, \"melspectrogram\").shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bdfc8f-4c7e-4df2-a17f-816188c40fbc",
   "metadata": {},
   "source": [
    "# Step 1 筛选优质的数据\n",
    "首先取出专家标注的部分，这些才是真正用来做监督学习的。\n",
    "\n",
    "然后\n",
    "1. 去除没有status词条的行\n",
    "2. 去除cough_detected小于0.8的行\n",
    "3. 去除quality不是good的行\n",
    "4. 仅保留专家标注的列，不再需要用户自己上报的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6cf6f-822f-4a82-9381-669d60553295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_physicians(df):\n",
    "    column_names = ['uuid', 'datetime', 'cough_detected', 'SNR', 'latitude', 'longitude', \n",
    "                    'age', 'gender', 'respiratory_condition', 'fever_muscle_pain', 'status', \n",
    "                    'quality', 'cough_type', 'dyspnea', 'wheezing', 'stridor', 'choking', \n",
    "                    'congestion', 'nothing', 'diagnosis', 'severity' ]\n",
    "    physician_01 = df.iloc[:, 0:21]\n",
    "    physician_01 = physician_01[physician_01.quality_1.notna()].reset_index(drop=True)\n",
    "    physician_01.columns = column_names\n",
    "\n",
    "    physician_02 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 21:31]], axis=1)\n",
    "    physician_02 = physician_02[physician_02.quality_2.notna()].reset_index(drop=True)\n",
    "    physician_02.columns = column_names\n",
    "\n",
    "    physician_03 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 31:41]], axis=1)\n",
    "    physician_03 = physician_03[physician_03.quality_3.notna()].reset_index(drop=True)\n",
    "    physician_03.columns = column_names\n",
    "\n",
    "    physician_04 = pd.concat([df.iloc[:, 0:11], df.iloc[:, 41:51]], axis=1)\n",
    "    physician_04 = physician_04[physician_04.quality_4.notna()].reset_index(drop=True)\n",
    "    physician_04.columns = column_names\n",
    "    return physician_01, physician_02, physician_03, physician_04\n",
    "    \n",
    "def process_csv(df):\n",
    "    #split by physicians\n",
    "    physician_01, physician_02, physician_03, physician_04 = split_by_physicians(df)\n",
    "    # combine into one dataframe\n",
    "    df = pd.concat([physician_01,physician_02,physician_03,physician_04]).reset_index(drop=True)  \n",
    "    # drop null status\n",
    "    df = df[df.status.notna()]\n",
    "    # drop cough_detected < 0.8\n",
    "    df = df[df.cough_detected >= 0.8 ]\n",
    "    # select good and ok quality\n",
    "    df = df[df.quality == 'good']\n",
    "    # shuffle\n",
    "    df = df.sample(frac=1).reset_index(drop=True) \n",
    "    df = df[['uuid', 'status','cough_type', 'dyspnea', 'wheezing', 'stridor', 'choking', 'congestion', 'severity']]\n",
    "    return df\n",
    "\n",
    "processed_df = process_csv(data_raw)\n",
    "processed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311035ee-bd28-469d-8e0f-62002399e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_df.shape)\n",
    "processed_df.groupby(\"status\")[\"uuid\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b47920-5731-4d50-8248-b95943496426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_cough(x,fs, cough_padding=0.2,min_cough_len=0.2, th_l_multiplier = 0.1, th_h_multiplier = 2):\n",
    "    #Preprocess the data by segmenting each file into individual coughs using a hysteresis comparator on the signal power                \n",
    "    cough_mask = np.array([False]*len(x))\n",
    "    \n",
    "    #Define hysteresis thresholds\n",
    "    rms = np.sqrt(np.mean(np.square(x)))\n",
    "    seg_th_l = th_l_multiplier * rms\n",
    "    seg_th_h =  th_h_multiplier*rms\n",
    "\n",
    "    #Segment coughs\n",
    "    coughSegments = []\n",
    "    padding = round(fs*cough_padding)\n",
    "    min_cough_samples = round(fs*min_cough_len)\n",
    "    cough_start = 0\n",
    "    cough_end = 0\n",
    "    cough_in_progress = False\n",
    "    tolerance = round(0.01*fs)\n",
    "    below_th_counter = 0\n",
    "    \n",
    "    for i, sample in enumerate(x**2):\n",
    "        if cough_in_progress:\n",
    "            if sample<seg_th_l:\n",
    "                below_th_counter += 1\n",
    "                if below_th_counter > tolerance:\n",
    "                    cough_end = i+padding if (i+padding < len(x)) else len(x)-1\n",
    "                    cough_in_progress = False\n",
    "                    if (cough_end+1-cough_start-2*padding>min_cough_samples):\n",
    "                        coughSegments.append(x[cough_start:cough_end+1])\n",
    "                        cough_mask[cough_start:cough_end+1] = True\n",
    "            elif i == (len(x)-1):\n",
    "                cough_end=i\n",
    "                cough_in_progress = False\n",
    "                if (cough_end+1-cough_start-2*padding>min_cough_samples):\n",
    "                    coughSegments.append(x[cough_start:cough_end+1])\n",
    "            else:\n",
    "                below_th_counter = 0\n",
    "        else:\n",
    "            if sample>seg_th_h:\n",
    "                cough_start = i-padding if (i-padding >=0) else 0\n",
    "                cough_in_progress = True\n",
    "    \n",
    "    return coughSegments, cough_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb85697-482f-4f5e-b938-ac6f80733d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def insert_into_df(df, row, idx):\n",
    "#     df2 = df.iloc[idx+1:, :]\n",
    "#     df = df.iloc[:idx, :]\n",
    "#     df.append(row)\n",
    "#     df = pd.concat(df, df2)\n",
    "#     return df\n",
    "\n",
    "# https://blog.csdn.net/sunmingyang1987/article/details/105486710\n",
    "def insert_addidx(df, row, idx):\n",
    "    df = df.reindex(index=df.index.insert(idx, str(idx)))\n",
    "    df.loc[str(idx)] = row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb92170-ac30-42ec-b725-1883cd40300b",
   "metadata": {},
   "source": [
    "# Step 2 切分音频并存储并创建meta文件csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e919f-685c-433a-8842-e3736c5019e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_length = 32306\n",
    "all_data, all_fname = [], []\n",
    "all_sr = []\n",
    "new_df = processed_df\n",
    "for idx in tqdm(range(len(processed_df))):\n",
    "    fname = processed_df.uuid.iloc[idx]\n",
    "    for ext in [\"webm\", \"wav\", \"ogg\"]:\n",
    "        path = ROOT+fname+'.'+ext\n",
    "        if os.path.exists(path):\n",
    "            break\n",
    "\n",
    "    # load sound sample\n",
    "    audio, sample_rate = librosa.load(path, mono=True)\n",
    "\n",
    "    # Segment each audio into individual coughs using a hysteresis comparator on the signal power\n",
    "    cough_segments, cough_mask = segment_cough(audio, sample_rate, min_cough_len=0.1, cough_padding=0.1, th_l_multiplier = 0.1, th_h_multiplier = 2)\n",
    "\n",
    "    # For each segment, resize to the same length(11025)\n",
    "    if len(cough_segments) > 0 :\n",
    "        i = 0\n",
    "        for audio in cough_segments:\n",
    "            i+=1\n",
    "            if len(audio) > 8000:\n",
    "                if len(audio) < audio_length:\n",
    "                    audio_pad = librosa.util.pad_center(data=audio, size=audio_length)\n",
    "                else:\n",
    "                    # audio_pad = audio[:audio_length] \n",
    "                    audio_pad = audio\n",
    "\n",
    "            # feature = extract_features(audio_pad, sample_rate)\n",
    "            #print(len(feature))\n",
    "            # all_data.append(feature)\n",
    "            all_data.append(audio_pad)\n",
    "            all_fname.append(fname)\n",
    "            all_sr.append(sample_rate)\n",
    "            new_df = pd.concat([new_df, processed_df.iloc[[idx], :]], axis=0)\n",
    "\n",
    "# uuid, X = np.array(all_fname), np.array(all_data)\n",
    "# # This may take some time, so go watch some Korean dramas first.\n",
    "# # uuid, X = load_features(processed_df)\n",
    "# print(uuid.shape)\n",
    "# print(X.shape)\n",
    "\n",
    "new_df = new_df.iloc[len(processed_df):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e85687-474c-48f3-b350-6902e97317f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(processed_df), processed_df.shape)\n",
    "print(len(new_df), new_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ec82d-aaed-478e-a819-dbe3d85ce4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"uuid\"] = processed_df[\"uuid\"]\n",
    "new_df = new_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d70bc5-62bc-4b29-9923-d5a50d0d5e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "for index, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "    # print(new_df.loc[ind,:][\"uuid\"])\n",
    "    new_df.iloc[index, :][\"uuid\"] = \"sound\"+(\"000\"+str(index))[-4:]+'_'+new_df.loc[index,:][\"uuid\"]\n",
    "    ind += 1\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc69257-9f65-465e-bbaf-30cd3e25129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"F:/DATAS/COUGHVID-public_dataset_v3/waveinfo_fewtoml_split.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f6cdee-9895-437a-94db-46012b2b4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "save_dir = \"F:/DATAS/COUGHVID-public_dataset_v3/coughvid_20211012_fine/\"\n",
    "for i in tqdm(range(len(all_data)), desc=\"save sound\"):\n",
    "    idx = \"000\"+str(i)\n",
    "    soundfile.write(save_dir+f\"sound{idx[-4:]}_{all_fname[i]}.wav\", all_data[i], 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f26726-379b-4d5a-a588-132f8ca81b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxmi, mini, mean = 0, 99999, 0\n",
    "for item in all_data:\n",
    "    maxmi = max(maxmi, len(item))\n",
    "    mini = min(mini, len(item))\n",
    "    mean += len(item)\n",
    "print(maxmi, mini, mean/len(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc95c39-612f-4ba5-a818-28d351470351",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
