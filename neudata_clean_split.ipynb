{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d187c82-8fee-4576-abfb-b47d317ce549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "from SED_CRNN import CRNN\n",
    "from readers.featurizer import Wave2Mel\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(r'C:/Program Files (zk)/PythonFiles/AClassification/SoundDL-CoughVID')\n",
    "ROOT = \"F:/DATAS/NEUCOUGHDATA_COUGHSINGLE/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7515d3-673b-489c-8129-423bb7283510",
   "metadata": {},
   "source": [
    "# Step 1 观察数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc182d8-391f-490d-863e-2f53c8e4edc5",
   "metadata": {},
   "source": [
    "## 1.1 尝试根据时间截取片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a384b0-824d-4c39-8cef-21123e9d9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_raw = pd.read_csv(ROOT+'neucough_metainfo_slice.txt', header=0, index_col=0)\n",
    "slice_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a8a23f-88f9-4996-8798-1c9cb4855b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min2sec(t: str):\n",
    "    parts = t.split(':')\n",
    "    return int(parts[0]) * 60 + float(parts[1])\n",
    "\n",
    "def read_audio(filepath: str, st=None, en=None):\n",
    "    # print(y.shape, sr)\n",
    "    # sr = 22050\n",
    "    if (st is not None) and (en is not None):\n",
    "        # st, en = int(st * sr), int(en * sr)\n",
    "        # print(\"st, en:\", st, en)\n",
    "        y, sr = librosa.load(filepath, offset=st, duration=en - st)\n",
    "        # print(\"y, sr:\", len(y), sr)\n",
    "    else:\n",
    "        y, sr = librosa.load(filepath, )\n",
    "        # print(\"y, sr:\", y, sr)\n",
    "    # print(y.shape)\n",
    "    # mel = w2m(torch.from_numpy(y))\n",
    "    return y, sr#  , mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9168857c-1027-467c-8a3e-23e07bd858d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, item in enumerate(slice_raw.itertuples()):\n",
    "    if idx >0:\n",
    "        break\n",
    "    name, st, en = item[0], item[1], item[2]\n",
    "    print(name, st, en)\n",
    "    audio_path = \"F:/DATAS/NEUCOUGHDATA_FULL/{}_audiodata_元音字母a.wav\".format(name)\n",
    "    y = read_audio(audio_path, st=min2sec(st), en=min2sec(en))\n",
    "    # plt.subplot(5, 1, idx+1)\n",
    "    plt.figure(idx, figsize=(14, 5))\n",
    "    plt.plot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38db1f-5d1a-4f75-a39f-3c5ad4c7b4ab",
   "metadata": {},
   "source": [
    "## 1.2 统计波形长度直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e6c6a-6325-4377-a571-c382d586e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.displot(slice_raw, x=\"slice\", bins=10, height=4, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29349585-c3a1-4c57-b01d-4fad41b8543a",
   "metadata": {},
   "source": [
    "# Step 2 统计Mel谱图的形状，统一长度，长的Crop短的Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bef63e2-8741-4293-bbdc-ecae62c0deff",
   "metadata": {},
   "source": [
    "## 2.1 读取、按时间切分、转换Mel谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab381b5b-dc64-4562-9346-d70852393c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Wave2Mel(object):\n",
    "    def __init__(self, sr,\n",
    "                 n_fft=1024,\n",
    "                 n_mels=128,\n",
    "                 win_length=1024,\n",
    "                 hop_length=512,\n",
    "                 power=2.0\n",
    "                 ):\n",
    "        self.mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=sr,\n",
    "                                                                  win_length=win_length,\n",
    "                                                                  hop_length=hop_length,\n",
    "                                                                  n_fft=n_fft,\n",
    "                                                                  n_mels=n_mels,\n",
    "                                                                  power=power)\n",
    "        self.amplitude_to_db = torchaudio.transforms.AmplitudeToDB(stype='power')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.amplitude_to_db(self.mel_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf39b4a-9571-4284-9523-7d5584cd6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_length_list = []\n",
    "sr_list = []\n",
    "w2m = Wave2Mel(sr=22050)\n",
    "fout = open(\"F:/DATAS/NEUCOUGHDATA_COUGHSINGLE/neucough_slicemel.txt\", 'w')\n",
    "fout.write(\"filename,duration,slice\\n\")\n",
    "for idx, item in tqdm(enumerate(slice_raw.itertuples()), desc=\"Wav2Mel:\"):\n",
    "    name, st, en = item[0], item[1], item[2]\n",
    "    audio_path = \"F:/DATAS/NEUCOUGHDATA_FULL/{}_audiodata_元音字母a.wav\".format(name)\n",
    "    y, sr = read_audio(audio_path, st=min2sec(st), en=min2sec(en))\n",
    "    sr_list.append(sr)\n",
    "\n",
    "    mel = w2m(torch.from_numpy(y))\n",
    "    dim, length = mel.data.numpy().shape\n",
    "    mel_length_list.append([name, len(y), length])\n",
    "    fout.write(\"{},{},{}\\n\".format(name, len(y), length))\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df18e87-980c-4412-9662-2b2bb06691b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_raw = pd.read_csv(ROOT+'neucough_slicemel.txt', header=0, index_col=0)\n",
    "mel_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642f985a-fa11-43ad-a59d-019d548bc58b",
   "metadata": {},
   "source": [
    "## 2.2 统计Mel谱的长度统计直方图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cb7d1-e21b-40e9-9aec-9633d4f3e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_raw[\"slice\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea37154-07f6-4d4a-b293-5242367b389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(mel_raw, x=\"slice\", bins=10, height=4, aspect=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d91a14-9e1c-4f4d-9a5a-47691afce044",
   "metadata": {},
   "source": [
    "## 2.3 统一长度，长的Crop短的Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405f82a-d936-48f6-a79c-9eacd726fc8e",
   "metadata": {},
   "source": [
    "### 当前存在一个问题：有的很长，可以随机截取多个，而不是只要一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63a734-9f97-4ab3-9994-bae919a5f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_length = 16\n",
    "for idx, item in enumerate(slice_raw.itertuples()):\n",
    "    name, st, en = item[0], item[1], item[2]\n",
    "    st, en = min2sec(st), min2sec(en)\n",
    "    audio_path = \"F:/DATAS/NEUCOUGHDATA_FULL/{}_audiodata_元音字母a.wav\".format(name)\n",
    "    y, sr = read_audio(audio_path, st=min2sec(st), en=min2sec(en))\n",
    "    mel = w2m(torch.from_numpy(y)).data.numpy()\n",
    "    dim, length = mel.shape\n",
    "    if length < 16:\n",
    "        new_mel = np.zeros((128, 16))\n",
    "        st = np.random.randint(0, (fixed_length-length+1)//2)\n",
    "        new_mel[:, st:st+16] = mel\n",
    "    elif length>16:\n",
    "        st = np.random.randint(0, (length+1-fixed_length)//2)\n",
    "        new_mel = mel[:, st:st+16]\n",
    "    else:\n",
    "        new_mel = mel\n",
    "        # print(\"wav, mel length:\", len(y), mel.shape)\n",
    "    print(new_mel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b1042d-90bf-4b8f-a7cc-32607a8eb68e",
   "metadata": {},
   "source": [
    "# Step 3 从原始音频中随机截取一些负样本，作为训练，和Region Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1a42fe-aa57-467e-b829-47d33650293d",
   "metadata": {},
   "source": [
    "## 寻找切分多大的范围内，波形的mel谱才是16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72dee96-c059-4fe3-8fa0-3334fb645897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min2sec(t: str):\n",
    "    parts = t.split(':')\n",
    "    return int(parts[0]) * 60 + float(parts[1])\n",
    "\n",
    "def get_rand_start(sec: int, wav_length:int, mode=\"left\", full_length: int=None, sr=22050):\n",
    "    \"\"\" 除法/不要写成//，会导致算什么都是0 \"\"\"\n",
    "    if mode==\"left\":\n",
    "        return np.random.randint(0, sec*sr-wav_length) / sr\n",
    "    elif mode==\"right\":\n",
    "        return np.random.randint(sec*sr, full_length-wav_length) / sr\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode of get_rand_start(mode=\\\"???\\\").\")\n",
    "\n",
    "def read_audio(filepath: str, st=None, en=None, duration=None):\n",
    "    # print(y.shape, sr)\n",
    "    # sr = 22050\n",
    "    if st is not None:\n",
    "        if en is not None:\n",
    "            # st, en = int(st * sr), int(en * sr)\n",
    "            # print(\"st, en:\", st, en)\n",
    "            y, sr = librosa.load(filepath, offset=st, duration=en - st)\n",
    "            # print(\"y, sr:\", len(y), sr)\n",
    "        elif duration is not None:\n",
    "            y, sr = librosa.load(filepath, offset=st, duration=duration)\n",
    "    else:\n",
    "        y, sr = librosa.load(filepath)\n",
    "            # print(\"y, sr:\", y, sr)\n",
    "    # print(y.shape)\n",
    "    # mel = w2m(torch.from_numpy(y))\n",
    "    return y, sr#  , mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5df510-f6fe-41fd-a4ad-3108a7199179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelling_by_IOU(st1:int, en1:int, st2:int, d2:int, mode=\"left\"):\n",
    "    print(st1,en1,st2,d2)\n",
    "    if mode==\"left\":\n",
    "        if st2+d2<st1:\n",
    "            return 0  # other\n",
    "        elif (st2+d2-st1)/(en1-st2) > 0.2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        raise Exception(\"Unknown mode of labelling_by_IOU(mode=\\\"???\\\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f94d7-d4e5-4e22-b885-26e9ab19a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2name = {0: \"non-cough\", 1:\"cough\"}\n",
    "fixed_length = 16\n",
    "for idx, item in enumerate(slice_raw.itertuples()):\n",
    "    name, st, en = item[0], item[1], item[2]\n",
    "    st, en = min2sec(st), min2sec(en)\n",
    "    print(\"st, en:\", st, en)\n",
    "    audio_path = \"F:/DATAS/NEUCOUGHDATA_FULL/{}_audiodata_元音字母a.wav\".format(name)\n",
    "    pos_sample, sr = read_audio(audio_path, st=st, en=en)\n",
    "    pos_mel = w2m(torch.from_numpy(pos_sample).to(torch.float32))\n",
    "    print(\"pos_sample:\", pos_sample.shape, pos_mel.shape)\n",
    "    print(\"label:\", 1, lab2name[1])\n",
    "    \n",
    "    mel16_rand_wavlen = np.random.randint(7680, 8192)  # Mel length: 16\n",
    "    print(\"wavlen:\", mel16_rand_wavlen/sr)\n",
    "    rand_start = get_rand_start(sec=st, wav_length=mel16_rand_wavlen, mode=\"left\", full_length=None, sr=22050)\n",
    "    print(\"rand_start:\", rand_start)\n",
    "    neg_sample, _ = read_audio(audio_path, st=rand_start, duration=mel16_rand_wavlen/sr)  # 除法/不要写成//，会导致算什么都是0\n",
    "    neg_mel = w2m(torch.from_numpy(neg_sample).to(torch.float32))\n",
    "    print(\"neg_sample:\", neg_sample.shape, neg_mel.shape)\n",
    "    gen_label = labelling_by_IOU(st1=st,en1=en,st2=rand_start,d2=mel16_rand_wavlen/sr)\n",
    "    print(\"label:\", gen_label, lab2name[gen_label])\n",
    "    while gen_label==1:\n",
    "        mel16_rand_wavlen = np.random.randint(7680, 8192)  # Mel length: 16\n",
    "        print(\"wavlen:\", mel16_rand_wavlen/sr)\n",
    "        rand_start = get_rand_start(sec=st, wav_length=mel16_rand_wavlen, mode=\"left\", full_length=None, sr=22050)\n",
    "        print(\"rand_start:\", rand_start)\n",
    "        neg_sample, _ = read_audio(audio_path, st=rand_start, duration=mel16_rand_wavlen/sr)  # 除法/不要写成//，会导致算什么都是0\n",
    "        print(\"neg_sample:\", neg_sample.shape)\n",
    "        gen_label = labelling_by_IOU(st1=st,en1=en,st2=rand_start,d2=mel16_rand_wavlen/sr)\n",
    "        print(\"label:\", gen_label, lab2name[gen_label])\n",
    "    print()\n",
    "    if idx>2:\n",
    "        print(\"idx:\", idx, mel16_rand_wavlen)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f1f85-f511-42a1-bae6-6baa4a20a373",
   "metadata": {},
   "source": [
    "# Step 4 均等分割一条数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d5b798-d152-4f10-a7b2-5f433814f818",
   "metadata": {},
   "source": [
    "## 4.1 KMeans聚类算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ee3512-59cb-4e39-819d-46c5e544627a",
   "metadata": {},
   "source": [
    "### RMS能量计算\n",
    "- 想法：带重叠滑动窗口获取样本，然后画图看一看是否可分\n",
    "- 然后多个文件一起，线性判别分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb199344-9ecf-4d4c-a3a0-5e42b9ffe129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4669210-bad0-422c-8273-16b8238407d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sig2rms(signal):\n",
    "    return np.sqrt(np.mean(np.square(signal)))\n",
    "\n",
    "def threshold2x(x, tr, mode=\"origin\"):\n",
    "    if mode==\"origin\":\n",
    "        return x if x > tr else 0\n",
    "    elif mode==\"label\":\n",
    "        return 1 if x > tr else 0\n",
    "    else:\n",
    "        raise Exception(\"Error mode of threshold2x {}, please choise from [\\\"origin\\\", \\\"label\\\"].\".format(mode))\n",
    "\n",
    "def file2rmslist(filepath):\n",
    "    fixed_length = 8191  # mel 16\n",
    "    overlap = 2048\n",
    "    wav_input, sr = librosa.load(sample_path)\n",
    "    N = len(wav_input)\n",
    "    st = 0\n",
    "    rms_list = []\n",
    "    while st < N:\n",
    "        sample = wav_input[st:st+fixed_length-overlap]\n",
    "        tmp_rms = sig2rms(sample)\n",
    "        rms_list.append(threshold2x(tmp_rms))\n",
    "        st += fixed_length\n",
    "    return rms\n",
    "fixed_length = 8191  # mel 16\n",
    "overlap = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143be8b6-7664-44f5-8272-285b7ef61bc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"F:/DATAS/NEUCOUGHDATA_FULL/\"\n",
    "sample_path = \"F:/DATAS/NEUCOUGHDATA_FULL/20240921104740_audiodata_元音字母a.wav\"\n",
    "file_list = []\n",
    "for item in os.listdir(\"F:/DATAS/NEUCOUGHDATA_FULL/\"):\n",
    "    if item[-3:]==\"wav\":\n",
    "        file_list.append(item)\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8ca25-d23b-4ac3-9a6d-6a3b24678fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold2x(x, tr, mode=\"origin\"):\n",
    "    if mode==\"origin\":\n",
    "        return x if x > tr else 0\n",
    "    elif mode==\"label\":\n",
    "        return 1 if x > tr else 0\n",
    "    else:\n",
    "        raise Exception(\"Error mode of threshold2x {}, please choise from [\\\"origin\\\", \\\"label\\\"].\".format(mode))\n",
    "\n",
    "def scale01(signal):\n",
    "    rate = 1. / max(signal)\n",
    "    return rate * np.array(signal)\n",
    "\n",
    "sample_path = random.choice(file_list)\n",
    "file_path = data_dir+sample_path\n",
    "print(sample_path)\n",
    "def file2signal(file_path):\n",
    "    wav_input, sr = librosa.load(file_path)\n",
    "    N = len(wav_input)\n",
    "    st = 0\n",
    "    rms_list = []\n",
    "    tmp_rms = sig2rms(scale01(wav_input))\n",
    "    tr = np.mean(tmp_rms) / 6.7\n",
    "    print(\"tr:\", tr)\n",
    "    while st < N:\n",
    "        sample = wav_input[st:st+fixed_length-overlap]\n",
    "        tmp_rms = sig2rms(sample)\n",
    "        # print(np.mean(tmp_rms))\n",
    "        rms_list.append(threshold2x(tmp_rms, tr))\n",
    "        st += fixed_length\n",
    "    return rms_list\n",
    "rms_list = file2signal(file_path)\n",
    "plt.figure(0)\n",
    "plt.plot(range(len(wav_input)), wav_input, c=\"black\")\n",
    "plt.figure(1)\n",
    "plt.stem(range(len(rms_list)), rms_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9f1d0b-ddc5-44c7-9793-23aed5823a19",
   "metadata": {},
   "source": [
    "## 4.2 尝试一下线性判别分析\n",
    "- 因为我需要的分类任务就是最精准的线性分类\n",
    "- 但是我感觉我不需要分类，我已经手动找阈值了，标签我都是通过阈值赋予的，那我还分什么类啊！！！\n",
    "- 说起来我的目标，不就是识别静音吗！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34754f5-0490-459a-93f1-f68ccb705c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39975ab-97f0-4696-8782-ee7eed4870d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5de5a689-5582-4867-ba2c-4a6ff824ba2f",
   "metadata": {},
   "source": [
    "## 进行Region Proposal的方法之我的想法\n",
    "- 根据我的调查，从RCNN开始就有的方法，先进行Region Proposal，具体方法，以及输出后的处理我不清楚，我怀疑不同region尺寸不一样大无法组成Batch。\n",
    "- 关注一下Bounding-Boxes的选取\n",
    "- YOLO里面提到了Anchor，锚框的选择值得关注\n",
    "- 我的想法则是最古老的方法，滑动窗口，带重叠。可以先试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c03d1c-8433-406b-9270-fd1b67074a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav2mel = Wave2Mel(sr=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a38c11-ee5a-4b51-abb6-99db53ff36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = [8192, 4068, 6144, 7168, 7679, 7680, 7681, 8191, 8192]\n",
    "for length in test_len:\n",
    "    test_x = torch.from_numpy(np.random.rand(length)).to(torch.float32)\n",
    "    x_mel = wav2mel(test_x)\n",
    "    print(length, x_mel.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0676ae4-a9d5-4f5f-8e2f-f5f7acdff009",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 8191\n",
    "for factor in range(2, int(np.sqrt(number))+2):\n",
    "    if number % factor == 0:\n",
    "        print(factor, number/factor)\n",
    "print(\"prime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a527d6-3522-47cb-868b-c348eb612adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_path = \"F:/DATAS/NEUCOUGHDATA_FULL/20240921104740_audiodata_元音字母a.wav\"\n",
    "# pool_size = [8, 8, 2]\n",
    "params = {\"pool_size\": [8, 8, 2], \"dropout_rate\": 0.0, \"batch_size\": 32, \"nb_cnn2d_filt\": 64,\n",
    "          \"rnn_size\": [128, 128], \"fnn_size\": [256, 128, 32]}\n",
    "device = torch.device(\"cuda\")\n",
    "model = CRNN(params=params).to(device)\n",
    "model.load_state_dict(torch.load(\"./runs/sed_crnn/{}/epoch_{}_sedmodel.pth\".format(\"202411152222\", 19)))\n",
    "model.eval()\n",
    "print(model)\n",
    "\n",
    "# sample_list, label_list = read_fullwave_file()\n",
    "lab2name = {0: \"non-cough\", 1: \"cough\"}\n",
    "fixed_length = 8191  # mel 16\n",
    "overlap = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4f150-64f3-4ee4-aa4c-4add96625558",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_input, sr = librosa.load(sample_path)\n",
    "N = len(wav_input)\n",
    "st = 0\n",
    "st_list = []\n",
    "yhat_list = []\n",
    "while st < N:\n",
    "    sample = wav_input[st:st+fixed_length-overlap]\n",
    "    x_mel = wav2mel(torch.from_numpy(sample).to(torch.float32))\n",
    "    x_mel = x_mel.unsqueeze(0).to(device)\n",
    "    print(\"start:{}, x_mel.shape:{}\".format(st, x_mel.shape))\n",
    "    with torch.no_grad():\n",
    "        y_pred, _ = model(x_mel)\n",
    "        y_hat = torch.argmax(y_pred, dim=-1)\n",
    "        st_list.append(st)\n",
    "        yhat_list.append(y_hat)\n",
    "    st += fixed_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fbb6f6-12fd-4cec-8d0d-e282d0f195d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_list = [item.data.cpu().numpy() for item in yhat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134d9b3-92a9-4ccd-a0f5-d301ba06a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.stem(range(len(yhat_list)), yhat_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a81d7d-e3b8-4b44-b40c-af96e9684aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc95c39-612f-4ba5-a818-28d351470351",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
