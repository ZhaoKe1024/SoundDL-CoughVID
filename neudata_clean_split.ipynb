{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d187c82-8fee-4576-abfb-b47d317ce549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "ROOT = \"F:/DATAS/NEUCOUGHDATA_COUGH/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea37154-07f6-4d4a-b293-5242367b389c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30078,) 22050\n",
      "1.3640816326530611\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load(ROOT+\"20240921195035_audiodata.wav\")\n",
    "print(y.shape, sr)\n",
    "print(y.shape[0]/sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83cbd2-6d43-4163-aad7-f797a69fc2e5",
   "metadata": {},
   "source": [
    "# 按静音切分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ca467-933f-4fc8-ac74-ddb56577c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = []\n",
    "for item in os.listdir(ROOT):\n",
    "    if item[-3:] == \"wav\":\n",
    "        name_list.append(item[:14])\n",
    "# print(name_list)\n",
    "\n",
    "annotated_df = pd.read_csv(ROOT+\"metainfo.csv\", delimiter=',', header=0, index_col=None)\n",
    "# annotated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64eed61d-d1fd-4641-93fc-38c4a244cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6727 20240921104740_audiodata_0.wav\n",
      "6761 20240921125652_audiodata_0.wav\n",
      "8589 20240921150814_audiodata_0.wav\n",
      "6747 20240921150814_audiodata_1.wav\n",
      "7761 20240921150814_audiodata_2.wav\n",
      "7246 20240921151655_audiodata_0.wav\n",
      "7016 20240921162153_audiodata_0.wav\n",
      "6893 20240927184318_audiodata_0.wav\n",
      "8029 20240927190536_audiodata_0.wav\n",
      "7212 20240927192134_audiodata_0.wav\n",
      "7824 20240927194322_audiodata_0.wav\n",
      "7914 20240927194322_audiodata_1.wav\n",
      "7266 20240927194322_audiodata_2.wav\n",
      "6779 20240930202847_audiodata_0.wav\n",
      "8359 20241002110641_audiodata_0.wav\n",
      "6804 20241002110641_audiodata_1.wav\n",
      "6952 20241002110641_audiodata_2.wav\n",
      "8007 20241003101029_audiodata_0.wav\n",
      "7396 20241003101029_audiodata_1.wav\n",
      "7110 20241003101029_audiodata_2.wav\n",
      "9555 20241003102826_audiodata_0.wav\n",
      "9103 20241003102826_audiodata_1.wav\n",
      "6811 20241003102826_audiodata_2.wav\n",
      "8210 20241003104654_audiodata_0.wav\n",
      "6874 20241003104654_audiodata_1.wav\n",
      "8232 20241003111239_audiodata_0.wav\n",
      "8053 20241003111239_audiodata_1.wav\n",
      "7905 20241003111239_audiodata_2.wav\n",
      "9919 20241004095955_audiodata_0.wav\n",
      "7258 20241004095955_audiodata_1.wav\n",
      "7076 20241004095955_audiodata_2.wav\n",
      "6982 20241007112843_audiodata_0.wav\n",
      "6949 20241007113300_audiodata_0.wav\n",
      "7734 20241007115117_audiodata_0.wav\n",
      "7629 20241007115117_audiodata_1.wav\n",
      "7835 20241007120925_audiodata_0.wav\n",
      "7930 20241007120925_audiodata_1.wav\n",
      "6770 20241007122442_audiodata_0.wav\n",
      "6989 20241007122442_audiodata_1.wav\n",
      "9012 20241007123748_audiodata_0.wav\n",
      "6891 20241007123748_audiodata_1.wav\n",
      "7908 20241007124945_audiodata_0.wav\n",
      "8556 20241007130243_audiodata_0.wav\n",
      "7064 20241007131854_audiodata_0.wav\n",
      "8861 20241007133311_audiodata_0.wav\n",
      "7143 20241007133311_audiodata_1.wav\n",
      "7320 20241007134846_audiodata_0.wav\n",
      "8014 20241007134846_audiodata_1.wav\n",
      "7284 20241007140335_audiodata_0.wav\n",
      "8031 20241007140335_audiodata_1.wav\n",
      "8791 20241007140335_audiodata_2.wav\n",
      "10155 20241007141527_audiodata_0.wav\n",
      "6794 20241007141527_audiodata_1.wav\n",
      "7455 20241007143159_audiodata_0.wav\n",
      "9071 20241007143159_audiodata_1.wav\n",
      "7219 20241007143159_audiodata_2.wav\n",
      "6628 20241007143159_audiodata_3.wav\n",
      "6762 20241007164006_audiodata_0.wav\n",
      "8390 20241007164006_audiodata_1.wav\n",
      "6641 20241007165403_audiodata_0.wav\n",
      "7756 20241007175513_audiodata_0.wav\n",
      "7112 20241007185426_audiodata_0.wav\n",
      "7290 20241007185426_audiodata_1.wav\n",
      "6708 20241007185426_audiodata_2.wav\n",
      "7614 20241007200648_audiodata_0.wav\n",
      "8465 20241007200648_audiodata_1.wav\n",
      "7373 20241007202823_audiodata_0.wav\n",
      "6894 20241007202823_audiodata_1.wav\n",
      "6999 20241007202823_audiodata_2.wav\n",
      "7451 20241007205519_audiodata_0.wav\n",
      "8349 20241008100510_audiodata_0.wav\n",
      "7141 20241008100510_audiodata_1.wav\n",
      "6853 20241008100510_audiodata_2.wav\n",
      "8915 20241008102123_audiodata_0.wav\n",
      "8074 20241008102123_audiodata_1.wav\n",
      "8080 20241008104918_audiodata_0.wav\n",
      "7928 20241008111431_audiodata_0.wav\n",
      "7618 20241008111431_audiodata_1.wav\n",
      "8334 20241008112151_audiodata_0.wav\n",
      "6988 20241008124335_audiodata_0.wav\n",
      "7785 20241008133113_audiodata_0.wav\n",
      "8086 20241008134455_audiodata_0.wav\n",
      "7713 20241008140709_audiodata_0.wav\n",
      "7195 20241008163249_audiodata_0.wav\n",
      "6792 20241008172507_audiodata_0.wav\n",
      "8381 20241008180138_audiodata_0.wav\n"
     ]
    }
   ],
   "source": [
    "def segment_cough(x,fs, cough_padding=0.2,min_cough_len=0.2, th_l_multiplier = 0.1, th_h_multiplier = 2):\n",
    "    #Preprocess the data by segmenting each file into individual coughs using a hysteresis comparator on the signal power                \n",
    "    cough_mask = np.array([False]*len(x))\n",
    "    \n",
    "    #Define hysteresis thresholds\n",
    "    rms = np.sqrt(np.mean(np.square(x)))\n",
    "    seg_th_l = th_l_multiplier * rms\n",
    "    seg_th_h =  th_h_multiplier*rms\n",
    "\n",
    "    #Segment coughs\n",
    "    coughSegments = []\n",
    "    padding = round(fs*cough_padding)\n",
    "    min_cough_samples = round(fs*min_cough_len)\n",
    "    cough_start = 0\n",
    "    cough_end = 0\n",
    "    cough_in_progress = False\n",
    "    tolerance = round(0.01*fs)\n",
    "    below_th_counter = 0\n",
    "    \n",
    "    for i, sample in enumerate(x**2):\n",
    "        if cough_in_progress:\n",
    "            if sample<seg_th_l:\n",
    "                below_th_counter += 1\n",
    "                if below_th_counter > tolerance:\n",
    "                    cough_end = i+padding if (i+padding < len(x)) else len(x)-1\n",
    "                    cough_in_progress = False\n",
    "                    if (cough_end+1-cough_start-2*padding>min_cough_samples):\n",
    "                        coughSegments.append(x[cough_start:cough_end+1])\n",
    "                        cough_mask[cough_start:cough_end+1] = True\n",
    "            elif i == (len(x)-1):\n",
    "                cough_end=i\n",
    "                cough_in_progress = False\n",
    "                if (cough_end+1-cough_start-2*padding>min_cough_samples):\n",
    "                    coughSegments.append(x[cough_start:cough_end+1])\n",
    "            else:\n",
    "                below_th_counter = 0\n",
    "        else:\n",
    "            if sample>seg_th_h:\n",
    "                cough_start = i-padding if (i-padding >=0) else 0\n",
    "                cough_in_progress = True\n",
    "    \n",
    "    return coughSegments, cough_mask\n",
    "\n",
    "all_data = []\n",
    "all_file = []\n",
    "for idx, row in enumerate(annotated_df.itertuples()):\n",
    "    fname = ROOT+str(row[1])+\"_audiodata.wav\"\n",
    "    audio, sample_rate = librosa.load(fname, mono=True)\n",
    "\n",
    "    # Segment each audio into individual coughs using a hysteresis comparator on the signal power\n",
    "    cough_segments, cough_mask = segment_cough(audio, sample_rate, min_cough_len=0.1, cough_padding=0.1, th_l_multiplier = 0.1, th_h_multiplier = 2)\n",
    "\n",
    "    # For each segment, resize to the same length(11025)\n",
    "    i = 0\n",
    "    for audio in cough_segments:\n",
    "        # print(len(audio))  # , len(audio)/22005)\n",
    "        all_data.append(len(audio))\n",
    "        all_file.append(str(row[1])+\"_audiodata_{}.wav\".format(i))\n",
    "        i += 1\n",
    "\n",
    "for j in range(len(all_data)):\n",
    "    print(all_data[j], all_file[j])\n",
    "# print(len(all_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eebda1-912a-4b4e-8daf-7b2d6d7e7732",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_length = 32306\n",
    "all_data, all_fname = [], []\n",
    "all_sr = []\n",
    "new_df = processed_df\n",
    "for idx in tqdm(range(len(processed_df))):\n",
    "    fname = processed_df.uuid.iloc[idx]\n",
    "    for ext in [\"webm\", \"wav\", \"ogg\"]:\n",
    "        path = ROOT+fname+'.'+ext\n",
    "        if os.path.exists(path):\n",
    "            break\n",
    "\n",
    "    # load sound sample\n",
    "    audio, sample_rate = librosa.load(path, mono=True)\n",
    "\n",
    "    # Segment each audio into individual coughs using a hysteresis comparator on the signal power\n",
    "    cough_segments, cough_mask = segment_cough(audio, sample_rate, min_cough_len=0.1, cough_padding=0.1, th_l_multiplier = 0.1, th_h_multiplier = 2)\n",
    "\n",
    "    # For each segment, resize to the same length(11025)\n",
    "    if len(cough_segments) > 0 :\n",
    "        i = 0\n",
    "        for audio in cough_segments:\n",
    "            i+=1\n",
    "            if len(audio) > 8000:\n",
    "                if len(audio) < audio_length:\n",
    "                    audio_pad = librosa.util.pad_center(data=audio, size=audio_length)\n",
    "                else:\n",
    "                    # audio_pad = audio[:audio_length] \n",
    "                    audio_pad = audio\n",
    "\n",
    "            # feature = extract_features(audio_pad, sample_rate)\n",
    "            #print(len(feature))\n",
    "            # all_data.append(feature)\n",
    "            all_data.append(audio_pad)\n",
    "            all_fname.append(fname)\n",
    "            all_sr.append(sample_rate)\n",
    "            new_df = pd.concat([new_df, processed_df.iloc[[idx], :]], axis=0)\n",
    "\n",
    "# uuid, X = np.array(all_fname), np.array(all_data)\n",
    "# # This may take some time, so go watch some Korean dramas first.\n",
    "# # uuid, X = load_features(processed_df)\n",
    "# print(uuid.shape)\n",
    "# print(X.shape)\n",
    "\n",
    "new_df = new_df.iloc[len(processed_df):, :]\n",
    "\n",
    "print(len(processed_df), processed_df.shape)\n",
    "print(len(new_df), new_df.shape)\n",
    "\n",
    "new_df[\"uuid\"] = processed_df[\"uuid\"]\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "ind = 0\n",
    "for index, row in tqdm(new_df.iterrows(), total=len(new_df)):\n",
    "    # print(new_df.loc[ind,:][\"uuid\"])\n",
    "    new_df.iloc[index, :][\"uuid\"] = \"sound\"+(\"000\"+str(index))[-4:]+'_'+new_df.loc[index,:][\"uuid\"]\n",
    "    ind += 1\n",
    "new_df\n",
    "\n",
    "new_df.to_csv(\"F:/DATAS/COUGHVID-public_dataset_v3/waveinfo_fewtoml_split.csv\", sep=',')\n",
    "\n",
    "import soundfile\n",
    "save_dir = \"F:/DATAS/COUGHVID-public_dataset_v3/coughvid_20211012_fine/\"\n",
    "for i in tqdm(range(len(all_data)), desc=\"save sound\"):\n",
    "    idx = \"000\"+str(i)\n",
    "    soundfile.write(save_dir+f\"sound{idx[-4:]}_{all_fname[i]}.wav\", all_data[i], 22050)\n",
    "\n",
    "maxmi, mini, mean = 0, 99999, 0\n",
    "for item in all_data:\n",
    "    maxmi = max(maxmi, len(item))\n",
    "    mini = min(mini, len(item))\n",
    "    mean += len(item)\n",
    "print(maxmi, mini, mean/len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc4155d-c7f8-418c-8158-0b2c83648737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a5284-50c4-402f-b261-2e54894eb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def insert_into_df(df, row, idx):\n",
    "#     df2 = df.iloc[idx+1:, :]\n",
    "#     df = df.iloc[:idx, :]\n",
    "#     df.append(row)\n",
    "#     df = pd.concat(df, df2)\n",
    "#     return df\n",
    "\n",
    "# https://blog.csdn.net/sunmingyang1987/article/details/105486710\n",
    "def insert_addidx(df, row, idx):\n",
    "    df = df.reindex(index=df.index.insert(idx, str(idx)))\n",
    "    df.loc[str(idx)] = row\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce9971-e1c1-4235-8b5d-efac85a3b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "seed_value= 32 \n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# set variables\n",
    "ROOT = 'F:/DATAS/COUGHVID-public_dataset_v3/coughvid_20211012/'\n",
    "class_names = ['healthy','COVID-19','symptomatic']\n",
    "audio_length = 32306\n",
    "\n",
    "# load coughvid meta\n",
    "data_raw = pd.read_csv(ROOT+'metadata_compiled.csv', header=0, index_col=0)\n",
    "data_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485b4b9-8ccc-457b-b051-b140333f7e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_raw.groupby(\"status\")[\"uuid\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49ccca0-21d1-4fc1-8d22-74a9a87a3d9d",
   "metadata": {},
   "source": [
    "# Step3 读取切分后的数据，抽取特征，创建pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0efc14-70a9-42cc-ba07-924fe0839ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(ROOT+'waveinfo_fewtoml_split.csv', header=0, index_col=0)\n",
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f437a0-90c5-46b6-ab22-45c74b9d5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"labels:\")\n",
    "print(data_raw.groupby(\"status\")[\"uuid\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616a067-63fc-49be-8c69-c3374a781bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOP_LENGTH = 512        # number of samples between successive frames\n",
    "WINDOW_LENGTH = 512     # length of the window in samples\n",
    "N_MEL = 128             # number of Mel bands to generate\n",
    "\n",
    "def compute_melspectrogram_with_fixed_length(audio, sampling_rate, num_of_samples=86):\n",
    "    try:\n",
    "        # compute a mel-scaled spectrogram\n",
    "        melspectrogram = librosa.feature.melspectrogram(y=audio, \n",
    "                                                        sr=sampling_rate, \n",
    "                                                        hop_length=HOP_LENGTH,\n",
    "                                                        win_length=WINDOW_LENGTH, \n",
    "                                                        n_mels=N_MEL)\n",
    "\n",
    "        # convert a power spectrogram to decibel units (log-mel spectrogram)\n",
    "        melspectrogram_db = librosa.power_to_db(melspectrogram, ref=np.max)\n",
    "        \n",
    "        melspectrogram_length = melspectrogram_db.shape[1]\n",
    "        # # pad or fix the length of spectrogram \n",
    "        # if melspectrogram_length != num_of_samples:\n",
    "        #     melspectrogram_db = librosa.util.fix_length(melspectrogram_db, \n",
    "        #                                                 size=num_of_samples, \n",
    "        #                                                 axis=1, \n",
    "        #                                                 constant_values=(0, -80.0))\n",
    "        # print(melspectrogram_db.shape)\n",
    "    except Exception as e:\n",
    "        print(\"\\nError encountered while parsing files\\n>>\", e)\n",
    "        return None \n",
    "    \n",
    "    return melspectrogram_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63a734-9f97-4ab3-9994-bae919a5f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_length = 32306\n",
    "# sample_rate = 22050\n",
    "all_data = []\n",
    "all_fname = []\n",
    "all_sr = []\n",
    "all_labels = []\n",
    "term1 = []\n",
    "term2 = []\n",
    "term3 = []\n",
    "term4 = []\n",
    "term5 = []\n",
    "term6 = []\n",
    "term7 = []\n",
    "m2l = {\"healthy\":0, \"COVID-19\":1}\n",
    "bool2int = {True: 0, False: 1}\n",
    "type2int={\"dry\": 0, \"wet\":1, \"unknown\": 2}\n",
    "seve2int = {\"mild\": 0, \"pseudocough\": 1, \"severe\": 2, \"unknown\": 3}\n",
    "# new_df = df_f\n",
    "maxi, mini = 0, 999999\n",
    "for idx, row in tqdm(enumerate(data_raw.itertuples()), total=len(data_raw)):\n",
    "    fname = ROOT+\"coughvid_20211012_fine/\" +getattr(row, \"uuid\")+\".wav\"\n",
    "    label = getattr(row, \"uuid\")\n",
    "    # load sound sample\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(fname, mono=True)\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        print(\"Error file:\", fname)\n",
    "        continue\n",
    "    maxi = max(maxi, audio.shape[0]/sample_rate)\n",
    "    mini = min(mini, audio.shape[0]/sample_rate)\n",
    "    \n",
    "\n",
    "    # feature = extract_features(audio_pad, sample_rate)\n",
    "    #print(len(feature))\n",
    "    # all_data.append(feature)\n",
    "    all_data.append(audio)\n",
    "    all_fname.append(fname)\n",
    "    all_labels.append(m2l[getattr(row, \"status\")])\n",
    "    all_sr.append(sample_rate)\n",
    "    term1.append(type2int[getattr(row, \"cough_type\")])\n",
    "    term2.append(bool2int[getattr(row, \"dyspnea\")])\n",
    "    term3.append(bool2int[getattr(row, \"wheezing\")])\n",
    "    term4.append(bool2int[getattr(row, \"stridor\")])\n",
    "    term5.append(bool2int[getattr(row, \"choking\")])\n",
    "    term6.append(bool2int[getattr(row, \"congestion\")])\n",
    "    term7.append(seve2int[getattr(row, \"severity\", 3)])\n",
    "#     new_df = pd.concat([new_df, df_f.iloc[[idx], :]], axis=0)\n",
    "# new_df = new_df.iloc[len(df_f):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6365400-aee1-4806-b3d7-8c1eaf44fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_data), len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c754c-9261-4884-859d-1cdfd7a8d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = []\n",
    "features_2 = []\n",
    "# \n",
    "for i in tqdm(range(len(all_data)),desc=\"calc..\"):\n",
    "    melspect = compute_melspectrogram_with_fixed_length(all_data[i], all_sr[i])\n",
    "    # print(melspec.shape)\n",
    "    # melspects.append(melspect)\n",
    "    # print(neg_idx, pos_idx)\n",
    "    if all_labels[i] == 0:\n",
    "        if len(features_1)<100:\n",
    "            features_1.append([melspect, 0, term1[i],term2[i],term3[i],term4[i],term5[i],term6[i],term7[i], 0])\n",
    "        else:\n",
    "            features_1.append([melspect, 0, term1[i],term2[i],term3[i],term4[i],term5[i],term6[i],term7[i], random.randint(1, 9)])\n",
    "    else:\n",
    "        if len(features_2)<100:\n",
    "            features_2.append([melspect, 1, term1[i],term2[i],term3[i],term4[i],term5[i],term6[i],term7[i], 0])\n",
    "        else:\n",
    "            features_2.append([melspect, 1, term1[i],term2[i],term3[i],term4[i],term5[i],term6[i],term7[i], random.randint(1, 9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3efa24-b953-47dc-8642-2463be7f3b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features.extend(features_1)\n",
    "features.extend(features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b93059-cf3d-43e3-99d2-26b73284ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "us8k_df = pd.DataFrame(features, columns=[\"melspectrogram\", \"label\", \"cough_type\", \"dyspnea\", \"wheezing\", \"stridor\", \"choking\", \"congestion\", \"severity\", \"fold\"])\n",
    "us8k_df.to_pickle(ROOT+\"coughvid_split_specattri.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523cc656-0ee1-4485-a6b2-6966afb3869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coughvid_df = pd.read_pickle(\"F:/DATAS/COUGHVID-public_dataset_v3/coughvid_split_specattri.pkl\")\n",
    "coughvid_df = coughvid_df.iloc[:, [0, 1, 2, 8, 9]]\n",
    "spectrogram, label, ty, seve, fold = coughvid_df.iloc[1]\n",
    "print(spectrogram.shape, label, ty, seve, fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d561af-417c-4941-a98c-f822941f3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(ROOT+\"coughvid_split_specattri.pkl\")\n",
    "print(df.head())\n",
    "neg_list = list(range(2076))\n",
    "pos_list = list(range(2076, 2850))\n",
    "# print(df.iloc[pos_list, :].groupby(\"label\")[\"melspectrogram\"].count())\n",
    "# print(df.iloc[neg_list, :].groupby(\"label\")[\"melspectrogram\"].count())\n",
    "print(df.groupby(\"cough_type\")[\"melspectrogram\"].count())\n",
    "print(df.groupby(\"dyspnea\")[\"melspectrogram\"].count())\n",
    "print(df.groupby(\"wheezing\")[\"melspectrogram\"].count())\n",
    "print(df.groupby(\"stridor\")[\"melspectrogram\"].count())\n",
    "print(df.groupby(\"choking\")[\"melspectrogram\"].count())\n",
    "print(df.groupby(\"congestion\")[\"melspectrogram\"].count())\n",
    "print(df.groupby(\"severity\")[\"melspectrogram\"].count())\n",
    "# for item in df.itertuples():\n",
    "    # print(getattr(item, \"melspectrogram\").shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311035ee-bd28-469d-8e0f-62002399e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(processed_df.shape)\n",
    "processed_df.groupby(\"status\")[\"uuid\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b47920-5731-4d50-8248-b95943496426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bc95c39-612f-4ba5-a818-28d351470351",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
