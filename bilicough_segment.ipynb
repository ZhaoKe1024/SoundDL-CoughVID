{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6859a56d-8ab2-4463-9152-86516521f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import seaborn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "BILICOUGH_ROOT = \"G:/DATAS-Medical/BILIBILICOUGH/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb19b5b-e149-4b11-a5f8-f58a246c428b",
   "metadata": {},
   "source": [
    "# 从mp4中提取wav音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f212d8-c5dc-4ec8-bdb4-7df727c3ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"金_属_音_咳_嗽\",\"剧烈的咳嗽。\",\"女孩感冒哮喘发作\",\"四个常见咳嗽声音最后一个要重视_听一下你属于哪一种\",\"我咳嗽的样子\", \"小朋友哮喘发作（看着好痛苦）\"]\n",
    "for name in names:\n",
    "    filename = BILICOUGH_ROOT + name + \".mp4\"\n",
    "    outname = BILICOUGH_ROOT + name + \".wav\"\n",
    "    os.system(\"ffmpeg -i {} -f wav -ar 44100 {}\".format(filename, outname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e23dd9-814f-485e-9d76-1bad3f9eb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for item in os.listdir(BILICOUGH_ROOT):\n",
    "    if item[-3:] == \"ass\":\n",
    "        file_list.append(item)\n",
    "name_mapper = open(BILICOUGH_ROOT + \"filename2index.txt\", 'w')\n",
    "for idx, item in enumerate(file_list):\n",
    "    print(BILICOUGH_ROOT+item)\n",
    "    name_mapper.write(\"bilicough_{},\".format((\"00\"+str(idx))[-3:])+item[:-4]+\"\\n\")\n",
    "name_mapper.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886cd55d-7be7-4c93-ab8c-a502f9b46899",
   "metadata": {},
   "source": [
    "# 读取整个音频并标注其咳嗽段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6810d0e-49f0-4371-a760-05a03e6f15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfin = open(BILICOUGH_ROOT + \"filename2index.txt\", 'r')\n",
    "name_list = []\n",
    "wavfin.readline()\n",
    "line = wavfin.readline()\n",
    "while line:\n",
    "    name_list.append(line.strip())\n",
    "    line = wavfin.readline()\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce785ab-ddd6-42c9-b895-a6768e4cd8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min2sec(t: str):\n",
    "    parts = t.split(':')\n",
    "    res = float(parts[-1])\n",
    "    f = 60\n",
    "    for i in range(len(parts)-1):\n",
    "        res += int(parts[len(parts)-2-i]) * f\n",
    "        f *= 60\n",
    "    return res\n",
    "\n",
    "def wav_plot(wavfile, label_list, idx=0):\n",
    "    y, sr = librosa.load(BILICOUGH_ROOT + wavfile)\n",
    "    print(\"sample rate:\", sr)\n",
    "    y_plt = np.array([])\n",
    "    for item in label_list:\n",
    "        st, en = int(min2sec(item[0])*sr), int(min2sec(item[1])*sr+1)\n",
    "        print(\"st, en:\", st, en)\n",
    "        seg = y[st: en]\n",
    "        y_plt = np.concatenate((y_plt, seg, np.zeros(8000)), axis=0)\n",
    "    plt.figure(idx)\n",
    "    plt.plot(y_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c99014-200b-4550-a320-9580457fa07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 17\n",
    "wavtest = name_list[idx] + \".wav\"\n",
    "asstest = name_list[idx] + \".ass\"\n",
    "print(wavtest, asstest)\n",
    "assfin = open(BILICOUGH_ROOT + asstest, 'r', encoding=\"utf-8\")\n",
    "label_list = []\n",
    "line = assfin.readline()\n",
    "while line.strip()!=\"[Events]\":\n",
    "    line = assfin.readline()\n",
    "    # print(line)\n",
    "assfin.readline()\n",
    "line = assfin.readline()\n",
    "while line:\n",
    "    # print(line)\n",
    "    parts = line.split(',')\n",
    "    if parts[9].strip() == \"useless\":\n",
    "        pass\n",
    "    else:\n",
    "        label_list.append([parts[1], parts[2], parts[9].strip()])\n",
    "    line = assfin.readline()\n",
    "for item in label_list:\n",
    "    print(item)\n",
    "wav_plot(wavtest, label_list, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fdd3ba-f90a-4fbc-b8e8-977304ffce92",
   "metadata": {},
   "source": [
    "### 批量绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b286e9-e058-44e3-9fdd-a85096df280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, name in enumerate(name_list):\n",
    "    wavtest = name_list[idx] + \".wav\"\n",
    "    asstest = name_list[idx] + \".ass\"\n",
    "\n",
    "    assfin = open(BILICOUGH_ROOT + asstest, 'r', encoding=\"utf-8\")\n",
    "    label_list = []\n",
    "    line = assfin.readline()\n",
    "    while line.strip()!=\"[Events]\":\n",
    "        line = assfin.readline()\n",
    "        # print(line)\n",
    "    assfin.readline()\n",
    "    line = assfin.readline()\n",
    "    while line:\n",
    "        # print(line)\n",
    "        parts = line.split(',')\n",
    "        if parts[9].strip() == \"useless\":\n",
    "            pass\n",
    "        else:\n",
    "            label_list.append([parts[1], parts[2], parts[9].strip()])\n",
    "        line = assfin.readline()\n",
    "    for item in label_list:\n",
    "        print(item)\n",
    "    \n",
    "    wav_plot(wavtest, label_list, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a4ecf-a529-4701-a5f2-56253347f4fb",
   "metadata": {},
   "source": [
    "# 二分类及其标注\n",
    "- 非咳嗽的标注：0，\"useless\", \"silence\", \"noise\"\n",
    "- 咳嗽的标注：1，其他都是"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ae047-e107-43fe-bc63-2afd66cc2b29",
   "metadata": {},
   "source": [
    "### 第一步，读取所有的ass文件\n",
    "- 查看标签有哪些，来自哪些文件\n",
    "- 查看标签的个数\n",
    "- 查看时长分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f97303-8e39-43a4-8519-aacbceb27a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavfin = open(\"G:/DATAS-Medical/BILIBILICOUGH/filename2index.txt\", 'r')\n",
    "name_list = []\n",
    "wavfin.readline()\n",
    "line = wavfin.readline()\n",
    "while line:\n",
    "    name_list.append(line.strip())\n",
    "    line = wavfin.readline()\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f86afd-b890-4401-b288-5f294824f54a",
   "metadata": {},
   "source": [
    "### 注意！此处有重要文件“bilicough_metainfo.csv”的创建和写入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf10f3-2085-4ae0-9bf5-43fc1d96ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name_list)\n",
    "label_dict = dict()\n",
    "label_names = [\"breathe\", \"cough\",\"clearthroat\",\"exhale\", \"hum\", \"inhale\",\"noise\", \"silence\", \"sniff\",\"speech\", \"vomit\",\"whooping\"]\n",
    "label_cnt = dict()\n",
    "name2label = {\"breathe\":0, \"cough\":2,\"clearthroat\":1,\"exhale\":3, \"hum\":4, \"inhale\":5,\"noise\":6, \"silence\":7, \"sniff\":8,\"speech\":9, \"vomit\":10,\"whooping\":11}\n",
    "# metainfo_file = open(\"G:/DATAS-Medical/BILIBILICOUGH/bilicough_metainfo.csv\", 'w')\n",
    "# metainfo_file.write(\"filename,st,en,labelfull,labelname,label\\n\")\n",
    "for idx, name in enumerate(name_list):\n",
    "    wavtest = name_list[idx] + \".wav\"\n",
    "    asstest = name_list[idx] + \".ass\"\n",
    "    assfin = open(\"G:/DATAS-Medical/BILIBILICOUGH/\" + asstest, 'r', encoding=\"utf-8\")\n",
    "    label_list = []\n",
    "    line = assfin.readline()\n",
    "    while line.strip()!=\"[Events]\":\n",
    "        line = assfin.readline()\n",
    "        # print(line)\n",
    "    assfin.readline()\n",
    "    line = assfin.readline()\n",
    "    while line:\n",
    "        # print(line)\n",
    "        parts = line.split(',')\n",
    "        lab_tmp = parts[9].strip()\n",
    "        if lab_tmp == \"useless\":\n",
    "            pass\n",
    "        # if lab_tmp == \"clearingthroat\":\n",
    "        #     print(name_list[idx])\n",
    "        else:\n",
    "            label_list.append([parts[1], parts[2], lab_tmp])\n",
    "            if lab_tmp not in label_dict:\n",
    "                label_dict[lab_tmp] = 1\n",
    "            else:\n",
    "                label_dict[lab_tmp] = label_dict.get(lab_tmp)+1\n",
    "            \n",
    "            label = None\n",
    "            if lab_tmp[:3] == \"hum\":\n",
    "                label = lab_tmp[:3]\n",
    "            elif lab_tmp[:5] in [\"cough\", \"noise\", \"sniff\", \"vomit\"]:\n",
    "                label = lab_tmp[:5]\n",
    "            elif lab_tmp[:6] in [\"inhale\", \"exhale\", \"speech\"]:\n",
    "                label = lab_tmp[:6]\n",
    "            elif lab_tmp[:7] in [\"breathe\",\"silence\"]:\n",
    "                label = lab_tmp[:7]\n",
    "            elif lab_tmp[:8] in [\"whooping\"]:\n",
    "                label = lab_tmp[:8]\n",
    "            elif lab_tmp[:11] in [\"clearthroat\"]:\n",
    "                label = lab_tmp[:11]\n",
    "            else:\n",
    "                print(lab_tmp, name_list[idx])\n",
    "                raise Exception(\"Unknown Class.\")\n",
    "                \n",
    "            if label not in label_cnt:\n",
    "                label_cnt[label] = 1\n",
    "            else:\n",
    "                label_cnt[label] = label_cnt.get(label)+1\n",
    "            # metainfo_file.write(\"{},{},{},{},{},{}\\n\".format(name_list[idx], parts[1], parts[2] ,lab_tmp, label,name2label[label]))\n",
    "        line = assfin.readline()\n",
    "# metainfo_file.close()\n",
    "# for item in label_list:\n",
    "#     print(item)\n",
    "print(\"标签分布：\")\n",
    "for k,v in label_dict.items():\n",
    "    print(\"key:{},\\tcount:{}\".format(k,v))\n",
    "print(\"---------------=============----------------\")\n",
    "for k,v in label_cnt.items():\n",
    "    print(\"key:{},\\tcount:{}\".format(k,v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60827187-b175-4f71-8956-7d8f8919f6e2",
   "metadata": {},
   "source": [
    "## 读取metainfo文件，创建不同任务的标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b246fe-6f74-4bf1-8511-ef846f34b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa64cd-a052-474e-ae95-2ace3bc1419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf = pd.read_csv(\"G:/DATAS-Medical/BILIBILICOUGH/bilicough_metainfo.csv\", delimiter=',', header=0, index_col=None, encoding=\"ansi\")\n",
    "print(metadf)\n",
    "newdf = metadf\n",
    "newdf[\"binlab\"] = newdf[\"label\"].apply(lambda x:2 if x==2 else 0)\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3935d8-d97a-4928-81d8-e01175cb97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min2sec(t: str):\n",
    "    parts = t.split(':')\n",
    "    res = float(parts[-1])\n",
    "    f = 60\n",
    "    for i in range(len(parts)-1):\n",
    "        res += int(parts[len(parts)-2-i]) * f\n",
    "        f *= 60\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31951ffd-14a8-43cf-b695-1f606dd3d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_list = []\n",
    "sr = 22050\n",
    "for ind, item in enumerate(metadf.itertuples()):\n",
    "    # print(\"key:{},\\tcount:{}, st:{}, en:{}, {}, {}\".format(ind, item[1], item[2], item[3], item[5], item[6]))\n",
    "    if item[6] == 2:\n",
    "        st, en = int(min2sec(item[2])*sr), int(min2sec(item[3])*sr+1)\n",
    "        sn = en - st\n",
    "        sn_list.append((en - st)/22050)\n",
    "\n",
    "# plt.hist(sn_list, bins=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe1780-6833-4eed-901f-ad799a0f6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "trs = [0.3, 0.5, 0.8, 1.0, 1.2, 1.5, 1.7, 2.0, 2.5, 10]\n",
    "cnt_list = [0] * len(trs)\n",
    "for sn in sn_list:\n",
    "    for i in range(len(trs)):\n",
    "        if sn < trs[i]+0.1:\n",
    "            cnt_list[i] += 1\n",
    "            break\n",
    "plt.figure(0)\n",
    "plt.bar([str(item) for item in trs], cnt_list, width=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5216f0-c083-4ccc-a333-44fbfa07591f",
   "metadata": {},
   "source": [
    "# 通过滑动窗口截取数据片段\n",
    "## 在所有数据中获取有效片段和无效片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec1e2f-ff67-4c69-8113-f2cbbd9cbfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "# newdf.groupby(\"binlab\").count()\n",
    "def min2sec(t: str):\n",
    "    parts = t.split(':')\n",
    "    res = float(parts[-1])\n",
    "    f = 60\n",
    "    for i in range(len(parts)-1):\n",
    "        res += int(parts[len(parts)-2-i]) * f\n",
    "        f *= 60\n",
    "    return res\n",
    "\n",
    "def get_bilicough_dataset():\n",
    "    ROOT = \"G:/DATAS-Medical/BILIBILICOUGH/\"\n",
    "    metadf = pd.read_csv(ROOT+\"bilicough_metainfo.csv\", delimiter=',', header=0, index_col=None, usecols=[0,1,2,5], encoding=\"ansi\")\n",
    "    print(metadf)\n",
    "    cur_fname = None\n",
    "    cur_wav = None\n",
    "    data_length = None\n",
    "    sample_list = []\n",
    "    label_list = []\n",
    "    sr_list = []\n",
    "    pre_st, pre_en = None, None\n",
    "    # filename\tst\ten\tlabelfull\tlabelname\tlabel\tbinlab\n",
    "    for ind, item in enumerate(metadf.itertuples()):\n",
    "        if (cur_fname != item[1]) or (cur_fname is None):\n",
    "            cur_fname = item[1]\n",
    "            cur_wav, sr = librosa.load(ROOT+cur_fname+\".wav\")\n",
    "            if sr not in sr_list:\n",
    "                sr_list.append(sr)\n",
    "            data_length = sr\n",
    "        st, en = int(min2sec(item[2])*sr), int(min2sec(item[3])*sr+1)\n",
    "        if en > len(cur_wav):\n",
    "            en = len(cur_wav)\n",
    "        if en - st < 100:\n",
    "            raise Exception(\"Error Index.\")\n",
    "        sn = en - st\n",
    "        # sec = (en - st)/22050\n",
    "        if (pre_en is None):\n",
    "            if st >= data_length:\n",
    "                st_pos = 0\n",
    "                ind = 0\n",
    "                while st_pos + data_length <= st:\n",
    "                    # if len(cur_wav[st_pos:st_pos+data_length]) != sr:\n",
    "                    #     raise Exception(\"Error Length.\")\n",
    "                    sample_list.append(cur_wav[st_pos:st_pos+data_length])\n",
    "                    label_list.append(0)\n",
    "                    st_pos += data_length\n",
    "                    ind += 1\n",
    "                    if ind >2:\n",
    "                        break\n",
    "                sample_list.append(cur_wav[st-data_length:st])\n",
    "                label_list.append(0)\n",
    "        else:\n",
    "            if st - pre_en >= sr:\n",
    "                st_pos = pre_en\n",
    "                ind = 0\n",
    "                while st_pos + data_length <= st:\n",
    "                    # if len(cur_wav[st_pos:st_pos+data_length]) != sr:\n",
    "                    #     raise Exception(\"Error Length.\")\n",
    "                    sample_list.append(cur_wav[st_pos:st_pos+data_length])\n",
    "                    label_list.append(0)\n",
    "                    st_pos += data_length\n",
    "                    ind += 1\n",
    "                    if ind > 2:\n",
    "                        break\n",
    "                sample_list.append(cur_wav[st-data_length:st])\n",
    "                label_list.append(0)\n",
    "        label = int(item[4])\n",
    "        if sn==data_length:\n",
    "            # if len(cur_wav[st:en]) != sr:\n",
    "            #     raise Exception(\"Error Length.\")\n",
    "            sample_list.append(cur_wav[st:en])\n",
    "            if label in [6, 7]:\n",
    "                label_list.append(0)\n",
    "            else:\n",
    "                label_list.append(1)\n",
    "        elif sn < data_length:\n",
    "            new_sample = np.zeros(data_length)\n",
    "            # print(st, en, sn, len(cur_wav), item[1])\n",
    "            if en <= len(cur_wav):\n",
    "                new_sample[:sn] = cur_wav[st:en]\n",
    "            else:\n",
    "                new_sample[:sn] = cur_wav[len(cur_wav)-sn:len(cur_wav)]\n",
    "            # if len(new_sample) != sr:\n",
    "            #     raise Exception(\"Error Length.\")\n",
    "            sample_list.append(new_sample)\n",
    "            if label in [6, 7]:\n",
    "                label_list.append(0)\n",
    "            else:\n",
    "                label_list.append(1)\n",
    "        else:\n",
    "            cnt_sum = sn // data_length + 1\n",
    "            res = cnt_sum * data_length - sn\n",
    "            overlap = res // (cnt_sum-1)\n",
    "            st_pos = st\n",
    "            while st_pos + data_length < en:\n",
    "                # if len(cur_wav[st_pos:st_pos+data_length]) < data_length: \n",
    "                #     tmp_length = len(cur_wav[st_pos:st_pos+data_length])\n",
    "                #     print(data_length, tmp_length)\n",
    "                #     # raise Exception(\"Error Length.\")\n",
    "                #     print(\"Error Length.\")\n",
    "                #     new_sample = np.zeros(data_length)\n",
    "                #     new_sample[:tmp_length] = cur_wav[st_pos:st_pos+data_length]\n",
    "                #     sample_list.append(new_sample)\n",
    "                # else:\n",
    "                #     sample_list.append(cur_wav[st_pos:st_pos+data_length])  \n",
    "                sample_list.append(cur_wav[st_pos:st_pos+data_length])                \n",
    "                if label in [6, 7]:\n",
    "                    label_list.append(0)\n",
    "                else:\n",
    "                    label_list.append(1)\n",
    "                st_pos += data_length - overlap\n",
    "            sample_list.append(cur_wav[en-data_length:en])\n",
    "            label_list.append(1)\n",
    "        pre_st, pre_en = st, en\n",
    "    print(\"sound count:{}, all count:{}.\".format(sum(label_list), len(label_list)))\n",
    "    print(sr_list)\n",
    "    return sample_list, label_list\n",
    "\n",
    "sample_list, label_list = get_bilicough_dataset()\n",
    "length_list = []\n",
    "for item in sample_list:\n",
    "    if len(item) not in length_list:\n",
    "        length_list.append(len(item))\n",
    "print(length_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ce1bd-7293-45fd-a12d-7103a4ac0b29",
   "metadata": {},
   "source": [
    "## 在另外下载的白噪声数据中截取部分用于充实数据的无效片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7f630-9535-4746-b068-742a6195ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "def load_bilinoise_dataset():\n",
    "    NOISE_ROOT = \"G:/DATAS-Medical/BILINOISE/\"\n",
    "    noise_length = None\n",
    "    filter_length = 25\n",
    "    ind = 0\n",
    "    new_noise_list = []\n",
    "    for item in os.listdir(NOISE_ROOT):\n",
    "        if item[-4:] == \".wav\" and len(item)>=filter_length:\n",
    "            cur_fname = NOISE_ROOT+item\n",
    "            cur_wav, sr = librosa.load(cur_fname)\n",
    "            noise_length = sr\n",
    "            L = len(cur_wav)\n",
    "            st_pos = np.random.randint(0, L-noise_length)\n",
    "            new_noise_list.append(cur_wav[st_pos:st_pos+noise_length])\n",
    "            # print(NOISE_ROOT+item)\n",
    "        ind += 1\n",
    "        if ind > 18:\n",
    "            break\n",
    "    for item in new_noise_list:\n",
    "        print(len(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59d85b-1441-4c0c-ab38-b266f30cd0a1",
   "metadata": {},
   "source": [
    "# 创建神经网络\n",
    "\n",
    "## 注意到，频域决定类别、幅值和时长是干扰因素，因为想办法在这里入手\n",
    "### 频域多用全连接而不是卷积池化\n",
    "### 幅值多用normalization\n",
    "### 时长采用多尺度叠加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea7f790-40e7-467b-90b5-a0db4b6331c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ae9ff8-46b2-4e36-8b00-25b287feb82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 20])\n",
      "torch.Size([32, 64, 32, 11])\n"
     ]
    }
   ],
   "source": [
    "class TDNN(nn.Module):\n",
    "    def __init__(self, window=1024, overlap=768):\n",
    "        super(TDNN, self).__init__()\n",
    "        self.tdnn = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=window, stride=window-overlap, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2),\n",
    "            nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.tdnn(x)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)\n",
    "\n",
    "class AudioClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AudioClassifier, self).__init__()\n",
    "        self.tdnn = TDNN()\n",
    "        self.cnn = CNN()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 55 + 64 * 11 * 11, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, waveform, melspectrogram):\n",
    "        tdnn_out = self.tdnn(waveform)\n",
    "        cnn_out = self.cnn(melspectrogram)\n",
    "        tdnn_out = tdnn_out.view(tdnn_out.size(0), -1)\n",
    "        cnn_out = cnn_out.view(cnn_out.size(0), -1)\n",
    "        combined = torch.cat((tdnn_out, cnn_out), dim=1)\n",
    "        return self.fc(combined)\n",
    "\n",
    "tdnn_module = TDNN(window=1024, overlap=768)\n",
    "cnn_module = CNN()\n",
    "cls_module = AudioClassifier()\n",
    "\n",
    "x_wav = torch.rand(size=(32, 22050))\n",
    "x_mel = torch.rand(size=(32, 128, 44))\n",
    "print(tdnn_module(x_wav.unsqueeze(1)).shape)\n",
    "print(cnn_module(x_mel.unsqueeze(1)).shape)\n",
    "\n",
    "# print(cls_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e8b81-cb9a-4826-bdab-3643cb809bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设你已经有了train_loader和valid_loader\n",
    "train_loader = DataLoader(...)\n",
    "valid_loader = DataLoader(...)\n",
    "\n",
    "# 初始化模型、损失函数和优化器\n",
    "model = AudioClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练流程\n",
    "def train(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (waveform, melspectrogram, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(waveform, melspectrogram)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:\n",
    "                print(f'Epoch [{epoch + 1}/{epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 10:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "# 验证流程\n",
    "def validate(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for waveform, melspectrogram, labels in valid_loader:\n",
    "            outputs = model(waveform, melspectrogram)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy of the model on the validation set: {100 * correct / total:.2f}%')\n",
    "\n",
    "# 训练和验证\n",
    "train(model, train_loader, criterion, optimizer, epochs=10)\n",
    "validate(model, valid_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e2521b-7e7d-4339-956d-ad3cbd38a0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3db72-375b-4256-9e1a-8c2b8a415d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,43,])\n",
    "b = np.array([5,76,8,])\n",
    "c = np.array([4,8,6])\n",
    "print(np.concatenate((np.array([]), a, b,c), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a6ccf-c3bb-4ed3-a770-0f76919066fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr= np.array([1,5,7,8,65,4,6,8,9,0])\n",
    "print(arr[8:15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
