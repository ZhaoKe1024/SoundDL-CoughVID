{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255c8dea-596d-4d95-a154-f1c4a151068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:/Program Files (zk)/PythonFiles/AClassification/AudioClassification-CoughVID')\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from models.conv_vae import ConvVAE\n",
    "\n",
    "from readers.coughvid_reader import CoughVID_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2528311b-bb30-48cf-92b4-416689eb2ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11297 3788\n",
      "11297 3788\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def CoughVID_NormalAnomaly(filename=\"./datasets/waveinfo_annotation.csv\", istrain=True, isdemo=False):\n",
    "    healthy_p_list = []\n",
    "    unhealthy_p_list = []\n",
    "    healthy_label_list = []\n",
    "    unhealthy_label_list = []\n",
    "    # healthy_anomaly_list = []\n",
    "    # unhealthy_anomaly_list = []\n",
    "    with open(filename, 'r') as fin:\n",
    "        fin.readline()\n",
    "        line = fin.readline()\n",
    "        while line:\n",
    "            parts = line.split(',')\n",
    "            status = int(parts[2])\n",
    "            if status == 0:\n",
    "                healthy_p_list.append(parts[1])\n",
    "                healthy_label_list.append(np.array(parts[2], dtype=np.int64))\n",
    "                # healthy_anomaly_list.append(np.array(0, dtype=np.int64))\n",
    "            else:\n",
    "                \n",
    "                unhealthy_p_list.append(parts[1])\n",
    "                unhealthy_label_list.append(np.array(parts[2], dtype=np.int64))\n",
    "                # unhealthy_anomaly_list.append(np.array(1, dtype=np.int64))\n",
    "            line = fin.readline()\n",
    "    return healthy_p_list, healthy_label_list, unhealthy_p_list, unhealthy_label_list\n",
    "\n",
    "# print(len(healthy_anomaly_list))\n",
    "# print(len(unhealthy_anomaly_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39164a6f-15ea-4f5e-a1f0-622c3beb6504",
   "metadata": {},
   "source": [
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efd780a1-a0dc-4f78-8800-9e6c4dd330fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10400 10400\n",
      "897 897\n"
     ]
    }
   ],
   "source": [
    "healthy_p_list, healthy_label_list, unhealthy_p_list, unhealthy_label_list = CoughVID_NormalAnomaly()\n",
    "print(len(healthy_p_list), len(unhealthy_p_list))\n",
    "print(len(healthy_label_list), len(unhealthy_label_list))\n",
    "\n",
    "trp, trl, vap, val = healthy_p_list[:10400], healthy_label_list[:10400], healthy_p_list[10400:], healthy_label_list[10400:]\n",
    "print(len(trp), len(trl))\n",
    "print(len(vap), len(val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218ffd4-3e1d-4f8f-a96f-f44d6d9be2f2",
   "metadata": {},
   "source": [
    "## 最耗时的读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "630954a4-d9af-4046-8e38-90037a38753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|                                                                               | 0/11297 [00:00<?, ?it/s]C:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\audio.py:117: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, sample_rate = librosa.core.load(file)  # , dtype='float32')\n",
      "C:\\Users\\zhaoke\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Loading:   0%|                                                                     | 1/11297 [00:00<2:57:53,  1.06it/s]C:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\audio.py:117: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, sample_rate = librosa.core.load(file)  # , dtype='float32')\n",
      "C:\\Users\\zhaoke\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Loading:   0%|▏                                                                     | 33/11297 [00:03<17:42, 10.60it/s]C:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\audio.py:117: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples, sample_rate = librosa.core.load(file)  # , dtype='float32')\n",
      "C:\\Users\\zhaoke\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Loading:   2%|█                                                                    | 178/11297 [00:12<12:58, 14.28it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'av.audio.fifo.AudioFifo' object has no attribute '_samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'F:/DATAS/COUGHVID-public_dataset_v3/coughvid_20211012/0382e9af-26ed-4482-b570-37b8d2a7d76b.webm': Format not recognised.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\audio.py:117\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, file)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# samples, sample_rate = soundfile.read(file, dtype='float32')\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     samples, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# , dtype='float32')\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# 支持更多格式数据\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\librosa\\core\\audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\audioread\\ffdec.py:171\u001b[0m, in \u001b[0;36mFFmpegAudioFile.__init__\u001b[1;34m(self, filename, block_size)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Read relevant information from stderr.\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Start a separate thread to read the rest of the data from\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# stderr. This (a) avoids filling up the OS buffer and (b)\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;66;03m# collects the error output for diagnosis.\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\torch-0\\lib\\site-packages\\audioread\\ffdec.py:215\u001b[0m, in \u001b[0;36mFFmpegAudioFile._get_info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 215\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line:\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;66;03m# EOF and data not found.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mCoughVID_Dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m toc \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Dataset Creat Completely, cost time:\u001b[39m\u001b[38;5;124m\"\u001b[39m, toc\u001b[38;5;241m-\u001b[39mtic)\n",
      "File \u001b[1;32mC:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\coughvid_reader.py:46\u001b[0m, in \u001b[0;36mCoughVID_Dataset.__init__\u001b[1;34m(self, path_list, label_list)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwav_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm(path_list, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend_wav\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\coughvid_reader.py:55\u001b[0m, in \u001b[0;36mCoughVID_Dataset.append_wav\u001b[1;34m(self, file_path)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mappend_wav\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path):\n\u001b[1;32m---> 55\u001b[0m     audioseg \u001b[38;5;241m=\u001b[39m \u001b[43mAudioSegment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     audioseg\u001b[38;5;241m.\u001b[39mvad()\n\u001b[0;32m     57\u001b[0m     audioseg\u001b[38;5;241m.\u001b[39mresample(target_sample_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\audio.py:121\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[1;34m(cls, file)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# 支持更多格式数据\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     sample_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16000\u001b[39m\n\u001b[1;32m--> 121\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(samples, sample_rate)\n",
      "File \u001b[1;32mC:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\audio.py:645\u001b[0m, in \u001b[0;36mdecode_audio\u001b[1;34m(file, sample_rate)\u001b[0m\n\u001b[0;32m    642\u001b[0m frames \u001b[38;5;241m=\u001b[39m _group_frames(frames, \u001b[38;5;241m500000\u001b[39m)\n\u001b[0;32m    643\u001b[0m frames \u001b[38;5;241m=\u001b[39m _resample_frames(frames, resampler)\n\u001b[1;32m--> 645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m frames:\n\u001b[0;32m    646\u001b[0m     array \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mto_ndarray()\n\u001b[0;32m    647\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32mC:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\audio.py:684\u001b[0m, in \u001b[0;36m_resample_frames\u001b[1;34m(frames, resampler)\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_resample_frames\u001b[39m(frames, resampler):\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;66;03m# Add None to flush the resampler.\u001b[39;00m\n\u001b[1;32m--> 684\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(frames, [\u001b[38;5;28;01mNone\u001b[39;00m]):\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m resampler\u001b[38;5;241m.\u001b[39mresample(frame)\n",
      "File \u001b[1;32mC:\\Program Files (zk)\\PythonFiles\\AClassification\\AudioClassification-CoughVID\\readers\\audio.py:675\u001b[0m, in \u001b[0;36m_group_frames\u001b[1;34m(frames, num_samples)\u001b[0m\n\u001b[0;32m    672\u001b[0m     frame\u001b[38;5;241m.\u001b[39mpts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Ignore timestamp check.\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     fifo\u001b[38;5;241m.\u001b[39mwrite(frame)\n\u001b[1;32m--> 675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mfifo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_samples\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_samples:\n\u001b[0;32m    676\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fifo\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fifo\u001b[38;5;241m.\u001b[39m_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'av.audio.fifo.AudioFifo' object has no attribute '_samples'"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "train_dataset = CoughVID_Dataset(path_list=trp, label_list=trl)\n",
    "toc = time.time()\n",
    "print(\"Train Dataset Creat Completely, cost time:\", toc-tic)\n",
    "valid_dataset = CoughVID_Dataset(path_list=vap, label_list=val)\n",
    "toc = time.time()\n",
    "print(\"Valid Dataset Creat Completely, cost time:\", toc-tic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6182c20a-b507-4815-9eb4-c196b7372180",
   "metadata": {},
   "source": [
    "## 基本参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b00884-d8d5-4b7e-8ba1-39de78147e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"run_save_dir\": \"./runs/tdnn_coughvid/\",\n",
    "    \"model\":{\n",
    "        \"num_class\": 3,\n",
    "        \"input_length\": 94,\n",
    "        \"wav_length\": 48000,\n",
    "        \"input_dim\": 512,\n",
    "        \"n_mels\": 80,\n",
    "        },\n",
    "    \"fit\":{\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\" : 23,\n",
    "        \"start_scheduler_epoch\": 6\n",
    "        },\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "num_epoch = configs[\"fit\"][\"epochs\"]\n",
    "klw = 0.00025\n",
    "# istrain: 如果是评估环节，设为False，读取测试集，并且不创建optimizer\n",
    "# isdemo: 如果只是测试一下，设为True，仅读取32条数据方便快速测试是否有bug\n",
    "istrain, isdemo = True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99248bca-7165-4308-a835-8444b1d9e86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model and loss are on device: cuda\n",
      "Create TDNN, Adam with lr=1e-3, CosineAnnealingLR Shceduler\n",
      "Create VAELoss...\n"
     ]
    }
   ],
   "source": [
    "# model loss_function optimizer scheduler\n",
    "print(\"All model and loss are on device:\", device)\n",
    "model = ConvVAE(shape=(1, 94, 128), flat=False).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=5e-5)\n",
    "print(\"Create TDNN, Adam with lr=1e-3, CosineAnnealingLR Shceduler\")\n",
    "\n",
    "MSE_loss = nn.MSELoss(reduction=\"mean\")\n",
    "def vae_loss(X, X_hat, mean, logvar, kl_weight=0.0001):\n",
    "    reconstruction_loss = MSE_loss(X_hat, X)\n",
    "    KL_divergence = 0.5 * torch.sum(-1 - logvar + torch.exp(logvar) + mean ** 2)\n",
    "    # print(reconstruction_loss.item(), KL_divergence.item())\n",
    "    return reconstruction_loss + kl_weight * KL_divergence\n",
    "\n",
    "print(\"Create VAELoss...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5339a5-26c0-4e07-8131-255751c72979",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 测试模型正确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5003d8c6-ecb7-4b61-9a6b-3c07f00b60cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "# m = ConvVAE(shape=(1, 94, 128), flat=True).to(device)\n",
    "# x = torch.randn(size=(16, 1, 94, 128)).to(device)\n",
    "\n",
    "# # print(m(x).shape)\n",
    "# recon_mel, z, mean_lant, logvar_lant = m(x)  # (28-3+2p)/2+1\n",
    "# print(recon_mel.shape)\n",
    "# print(mean_lant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeac5efa-8088-4b83-b3a5-797555033849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行保存目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0e8e71-eefe-4c81-8cd7-691c951a1402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建运行保存文件 ./runs/tdnn_coughvid/202404251743_tdnn_focalloss/\n"
     ]
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d%H%M\", time.localtime())\n",
    "if istrain:\n",
    "    run_save_dir = configs[\"run_save_dir\"] + timestr + f'_tdnn_focalloss/'\n",
    "if not isdemo:\n",
    "    os.makedirs(run_save_dir, exist_ok=True)\n",
    "    print(\"创建运行保存文件\", run_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048bc7b-28c2-43d0-9b24-a245ee8d1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = []\n",
    "for epoch_id in range(configs[\"fit\"][\"epochs\"]):\n",
    "    # ---------------------------\n",
    "    # -----------TRAIN-----------\n",
    "    # ---------------------------\n",
    "    model.train()\n",
    "    for x_idx, (x_wav, y_label, _) in enumerate(tqdm(train_loader, desc=\"Training\")):\n",
    "        x_mel = w2m(x_wav).to(device)\n",
    "        y_label = torch.tensor(y_label, device=device)\n",
    "        # print(\"shape of x_mel:\", x_mel.shape)\n",
    "        optimizer.zero_grad()\n",
    "        recon_mel, _, mean_lantet, logvar_latent = model(x=x_mel)\n",
    "        # recon_loss = self.recon_loss(recon_spec, x_mel)\n",
    "        pred_loss = vae_loss(x_mel, recon_mel, mean_latent, logvar_latent)\n",
    "        pred_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if x_idx > 2:\n",
    "            history1.append(pred_loss.item())\n",
    "        if x_idx % 60 == 0:\n",
    "            print(f\"Epoch[{epoch_id}], mtid pred loss:{pred_loss.item():.4f}\")\n",
    "    if epoch_id >= configs[\"fit\"][\"start_scheduler_epoch\"]:\n",
    "        scheduler.step()\n",
    "\n",
    "    # ---------------------------\n",
    "    # -----------SAVE------------\n",
    "    # ---------------------------\n",
    "    plt.figure(0)\n",
    "    plt.plot(range(len(history1)), history1, c=\"green\", alpha=0.7)\n",
    "    plt.savefig(run_save_dir + f'cls_loss_iter_{epoch_id}.png')\n",
    "    plt.close()\n",
    "    # if epoch > 6 and epoch % 2 == 0:\n",
    "    os.makedirs(run_save_dir + f\"model_epoch_{epoch_id}/\", exist_ok=True)\n",
    "    tmp_model_path = \"{model}model_{epoch}.pth\".format(\n",
    "        model=run_save_dir + f\"model_epoch_{epoch_id}/\",\n",
    "        epoch=epoch_id)\n",
    "    torch.save(model.state_dict(), tmp_model_path)\n",
    "    # ---------------------------\n",
    "    # -----------TEST------------\n",
    "    # ---------------------------\n",
    "    model.eval()\n",
    "    heatmap_input = None\n",
    "    labels = None\n",
    "    for x_idx, (x_wav, y_label, _) in enumerate(tqdm(valid_loader, desc=\"Validate\")):\n",
    "        x_mel = w2m(x_wav).to(device)\n",
    "        y_label = torch.tensor(y_label, device=device)\n",
    "        _, z, _, _ = model(x=x_mel)\n",
    "        if x_idx == 0:\n",
    "            heatmap_input, labels = y_pred, y_label\n",
    "        else:\n",
    "            heatmap_input = torch.concat((heatmap_input, y_pred), dim=0)\n",
    "            labels = torch.concat((labels, y_label), dim=0)\n",
    "        # if x_idx * configs[\"fit\"][\"batch_size\"] > 800:\n",
    "        #     break\n",
    "    print(\"heatmap_input shape:\", heatmap_input.shape)\n",
    "    print(\"lables shape:\", labels.shape)\n",
    "    # if epoch > 3:\n",
    "    #     self.plot_reduction(resume_path=\"\", load_epoch=epoch, reducers=[\"heatmap\"])\n",
    "    heatmap_input = heatmap_input.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    calc_accuracy(pred_matrix=heatmap_input, label_vec=labels,\n",
    "                  save_path=run_save_dir + f\"/accuracy_epoch_{epoch_id}.txt\")\n",
    "    plot_heatmap(pred_matrix=heatmap_input, label_vec=labels,\n",
    "                 ticks=[\"healthy\", \"symptomatic\", \"COVID-19\"],\n",
    "                 save_path=run_save_dir + f\"/heatmap_epoch_{epoch_id}.png\")\n",
    "print(\"============== END TRAINING ==============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232978c-0828-4ce0-a5fa-c97bd47f1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集读取和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72c6ec-277c-4a40-ac62-6aba1997d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "tep, tel = CoughVID_Lists(filename=\"./datasets/waveinfo_annotation.csv\", istrain=False, isdemo=False)\n",
    "print(len(tep), len(tel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a8345-b588-4f87-94e2-2e4081efab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "test_dataset = CoughVID_Dataset(path_list=tep, label_list=tel)\n",
    "toc = time.time()\n",
    "print(\"Test Dataset Creat Completely, cost time:\", toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e0287-c4ac-4140-8549-2435fa85ff25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3026c34-9b89-4886-8e89-37ffc52bda1d",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
